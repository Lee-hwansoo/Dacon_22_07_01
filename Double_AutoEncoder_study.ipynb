{"cells":[{"cell_type":"markdown","metadata":{"id":"2jD9PzSjw_x7"},"source":["# AutoEncoder Study"]},{"cell_type":"markdown","metadata":{"id":"Qvdx2a32w_ye"},"source":["## Colab setting"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oFZV1LoMw_yh","executionInfo":{"status":"ok","timestamp":1658822274756,"user_tz":-540,"elapsed":41210,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"06dd16ad-08b8-4bb2-f9ce-04c05b508d78"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Colab\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-EZM11QFw_ys","executionInfo":{"status":"ok","timestamp":1658822280939,"user_tz":-540,"elapsed":3998,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["# Colab\n","import pandas as pd\n","train_df = pd.read_csv('./drive/MyDrive/data/train.csv')\n","train_df = train_df.drop(columns=['ID'])\n","val_df = pd.read_csv('./drive/MyDrive/data/val.csv')\n","val_df = val_df.drop(columns=['ID'])\n","test_df = pd.read_csv('./drive/MyDrive/data/test.csv')\n","test_df = test_df.drop(columns=['ID'])"]},{"cell_type":"markdown","metadata":{"id":"LJDqlr8Aw_yu"},"source":["## Import"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8CL_XI2Hw_yw","executionInfo":{"status":"ok","timestamp":1658822285332,"user_tz":-540,"elapsed":2451,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import random\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score"]},{"cell_type":"markdown","metadata":{"id":"yhrckT-8w_y3"},"source":["## Data Load"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"FO7pxbmcw_y4","executionInfo":{"status":"ok","timestamp":1658822285333,"user_tz":-540,"elapsed":23,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["# Local\n","# train_df = pd.read_csv('./data/train.csv')\n","# train_df = train_df.drop(columns=['ID'])\n","# val_df = pd.read_csv('./data/val.csv')\n","# val_df = val_df.drop(columns=['ID'])\n","# test_df = pd.read_csv('./data/test.csv')\n","# test_df = test_df.drop(columns=['ID'])"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tqfn-Wibw_zO","executionInfo":{"status":"ok","timestamp":1658822285335,"user_tz":-540,"elapsed":23,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"efc6ee85-cca2-4d13-c81a-0dcd2a218495"},"outputs":[{"output_type":"stream","name":"stdout","text":["Normals 99.89 % of the dataset\n","Frauds 0.11 % of the dataset\n"]}],"source":["# validation data의 정상, 불량 거래 데이터 비율 확인\n","print('Normals', round(val_df['Class'].value_counts()[0]/len(val_df) * 100,2), '% of the dataset')\n","print('Frauds', round(val_df['Class'].value_counts()[1]/len(val_df) * 100,2), '% of the dataset')"]},{"cell_type":"markdown","metadata":{"id":"iqhlEWiXw_1U"},"source":["## Pytorch"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zPIdtOt0w_1W","executionInfo":{"status":"ok","timestamp":1658822285802,"user_tz":-540,"elapsed":7,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"ccbc037e-d6ac-406d-b543-d847d886c310"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using Device: cuda\n"]}],"source":["# device 설정, gpu 있을시 gpu사용\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(\"Using Device:\", device)"]},{"cell_type":"markdown","metadata":{"id":"rLH4Zic8w_1w"},"source":["### Hyper parameter"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"jydhpC5vw_1x","executionInfo":{"status":"ok","timestamp":1658822287809,"user_tz":-540,"elapsed":4,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["EPOCHS = 400\n","LR = 1e-2\n","BS = 16384\n","SEED = 123"]},{"cell_type":"markdown","metadata":{"id":"Uoffh2wuw_1z"},"source":["### Fix Seed"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"lsogABxmw_10","executionInfo":{"status":"ok","timestamp":1658822289509,"user_tz":-540,"elapsed":5,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(SEED) # Seed 고정"]},{"cell_type":"markdown","metadata":{"id":"yjc7_z-ww_12"},"source":[" ### Make DataSet    "]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ccZYmk45w_13","executionInfo":{"status":"ok","timestamp":1658822291783,"user_tz":-540,"elapsed":334,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["# eval_ mode를 통해 validation, 즉 평가를 위한 데이터 val.df와 train.df 분리\n","# val_df의 Class인 정상 거래, 비정상 거래 내용을 labels로, 나머지 feature 값을 df로 저장\n","# train_df의 값을 df로 저장\n","class MyDataset(Dataset):\n","    def __init__(self, df, eval_mode):\n","        self.df = df\n","        self.eval_mode = eval_mode\n","        if self.eval_mode:\n","            self.labels = self.df['Class'].values\n","            self.df = self.df.drop(columns=['Class']).values\n","        else:\n","            self.df = self.df.values\n","        \n","    def __getitem__(self, index):\n","        if self.eval_mode:\n","            self.x = self.df[index]\n","            self.y = self.labels[index]\n","            return torch.Tensor(self.x), self.y\n","        else:\n","            self.x = self.df[index]\n","            return torch.Tensor(self.x)\n","        \n","    def __len__(self):\n","        return len(self.df)"]},{"cell_type":"markdown","metadata":{"id":"xxx2FiSIw_15"},"source":["### Pytorch Data Load"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Lj20SOHPw_16","executionInfo":{"status":"ok","timestamp":1658822293500,"user_tz":-540,"elapsed":3,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["# shuffle을 통해 데이터 과적합해결(신경망이 데이터의 순서를 예측하지 못하게 한다)\n","train_dataset = MyDataset(df=train_df, eval_mode=False)\n","train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=2)\n","\n","\n","val_dataset = MyDataset(df = val_df, eval_mode=True)\n","val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=2)"]},{"cell_type":"markdown","metadata":{"id":"dxEGa7Sbw_18"},"source":["### AutoEncoder 구조(신경망)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"xvRnl4Flw_19","executionInfo":{"status":"ok","timestamp":1658822295361,"user_tz":-540,"elapsed":3,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["# neural network를 이용해서 AutoEncoder Layer 설정\n","# BatchNorm1d 정규화 레이어 사용\n","# LeakyReLU 활성화 함수 사용\n","class AutoEncoder(nn.Module):\n","    def __init__(self):\n","        super(AutoEncoder, self).__init__()\n","        self.Encoder = nn.Sequential(\n","            nn.Linear(30,64),\n","            nn.BatchNorm1d(64),\n","            nn.PReLU(),\n","            nn.Linear(64,128),\n","            nn.BatchNorm1d(128),\n","            nn.PReLU(),\n","        )\n","        self.Decoder = nn.Sequential(\n","            nn.Linear(128,64),\n","            nn.BatchNorm1d(64),\n","            nn.PReLU(),\n","            nn.Linear(64,30),\n","        )\n","        \n","    def forward(self, x):\n","        x = self.Encoder(x)\n","        x = self.Decoder(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"qkcAIrKhw_1-"},"source":["### Train"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"uXvK-WEGw_1_","executionInfo":{"status":"ok","timestamp":1658822296790,"user_tz":-540,"elapsed":3,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["class Trainer():\n","    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.scheduler = scheduler\n","        self.device = device\n","        # Loss Function\n","        self.criterion = nn.L1Loss().to(self.device)\n","        \n","    def fit(self, ):\n","        self.model.to(self.device)\n","        best_score = 0\n","        for epoch in range(EPOCHS):\n","            self.model.train()\n","            train_loss = []\n","            for x in iter(self.train_loader):\n","                x = x.float().to(self.device)\n","                # 역전파 단계 전에, optimizer 객체를 사용하여 (모델의 학습 가능한 가중치인) 갱신할\n","                # 변수들에 대한 모든 변화도(gradient)를 0으로 만듭니다. 이렇게 하는 이유는 기본적으로 \n","                # .backward()를 호출할 때마다 변화도가 버퍼(buffer)에 (덮어쓰지 않고) 누적되기\n","                # 때문입니다. 더 자세한 내용은 torch.autograd.backward에 대한 문서를 참조하세요.\n","                self.optimizer.zero_grad()\n","\n","                # AutoEncoder 통과한 예측값\n","                _x = self.model(x)\n","                loss = self.criterion(x, _x)\n","\n","                # 역전파 단계: 모델의 매개변수들에 대한 손실의 변화도를 계산합니다.\n","                loss.backward()\n","                # optimizer의 step 함수를 호출하면 매개변수가 갱신됩니다.\n","                self.optimizer.step()\n","\n","                train_loss.append(loss.item())\n","\n","            score = self.validation(self.model, 0.95)\n","            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n","\n","            if self.scheduler is not None:\n","                self.scheduler.step(score)\n","\n","            if best_score < score:\n","                best_score = score\n","                torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n","    \n","    def validation(self, eval_model, thr):\n","        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","        #  model.eval()는 이런 layer들의 동작을 inference(eval) mode로 바꿔준다는 목적\n","        eval_model.eval()\n","        pred = []\n","        true = []\n","        # torch.no_grad()의 주된 목적은 autograd(자동으로 gradient를 트래킹)를 끔으로써 메모리 사용량을 줄이고 연산 속도를 높히기 위함\n","        with torch.no_grad():\n","            for x, y in iter(self.val_loader):\n","                x = x.float().to(self.device)\n","\n","                _x = self.model(x)\n","                diff = cos(x, _x).cpu().tolist()\n","                #유사도 0.95보다 작은것은 이상거래 1, 아닌 것은 정상거래 0\n","                batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n","                pred += batch_pred\n","                true += y.tolist()\n","\n","        return f1_score(true, pred, average='macro')"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HCz4L786w_2B","executionInfo":{"status":"ok","timestamp":1658822958998,"user_tz":-540,"elapsed":660749,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"8a94ebb1-1e43-40d1-cb0d-431a83d81b7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : [0] Train loss : [0.5221804465566363] Val Score : [0.011953472826114834])\n","Epoch : [1] Train loss : [0.2989453354052135] Val Score : [0.31065869644030003])\n","Epoch : [2] Train loss : [0.19732261981282914] Val Score : [0.47505818666465444])\n","Epoch : [3] Train loss : [0.14701326404299056] Val Score : [0.5002556988120173])\n","Epoch : [4] Train loss : [0.11722193977662496] Val Score : [0.5083569226104104])\n","Epoch : [5] Train loss : [0.09686788597277232] Val Score : [0.5148608177924139])\n","Epoch : [6] Train loss : [0.0854653971535819] Val Score : [0.5251525663924234])\n","Epoch : [7] Train loss : [0.07923840518508639] Val Score : [0.5362409406460878])\n","Epoch : [8] Train loss : [0.07075492079768862] Val Score : [0.5438093350896822])\n","Epoch : [9] Train loss : [0.06794493538992745] Val Score : [0.5584269155630615])\n","Epoch : [10] Train loss : [0.06260997802019119] Val Score : [0.5747399991275138])\n","Epoch : [11] Train loss : [0.05903259292244911] Val Score : [0.5850157421008502])\n","Epoch : [12] Train loss : [0.059337065156017034] Val Score : [0.5994766565191958])\n","Epoch : [13] Train loss : [0.057686364012105126] Val Score : [0.6385281404460117])\n","Epoch : [14] Train loss : [0.05218461315546717] Val Score : [0.75467969893057])\n","Epoch : [15] Train loss : [0.050576359033584595] Val Score : [0.74464046996434])\n","Epoch : [16] Train loss : [0.04805245356900351] Val Score : [0.7376112450647377])\n","Epoch : [17] Train loss : [0.04880683443375996] Val Score : [0.752094104263044])\n","Epoch : [18] Train loss : [0.0478485498045172] Val Score : [0.7684388896488608])\n","Epoch : [19] Train loss : [0.05092073338372367] Val Score : [0.7713696202996474])\n","Epoch : [20] Train loss : [0.045549185680491586] Val Score : [0.762761970120889])\n","Epoch : [21] Train loss : [0.04561914822884968] Val Score : [0.777425875747303])\n","Epoch : [22] Train loss : [0.0451692459838731] Val Score : [0.777425875747303])\n","Epoch : [23] Train loss : [0.046388214720146995] Val Score : [0.777425875747303])\n","Epoch : [24] Train loss : [0.044461818145854134] Val Score : [0.7805557779616334])\n","Epoch : [25] Train loss : [0.043429030903748105] Val Score : [0.7837566139258728])\n","Epoch : [26] Train loss : [0.04159549730164664] Val Score : [0.7837566139258728])\n","Epoch : [27] Train loss : [0.04232100823095867] Val Score : [0.8009145358549308])\n","Epoch : [28] Train loss : [0.04254727331655366] Val Score : [0.8287186884323108])\n","Epoch : [29] Train loss : [0.043765947222709656] Val Score : [0.833113452596645])\n","Epoch : [30] Train loss : [0.039978107171399255] Val Score : [0.8422634702634115])\n","Epoch : [31] Train loss : [0.040503573204789846] Val Score : [0.872984830495149])\n","Epoch : [32] Train loss : [0.03756968943136079] Val Score : [0.8967110829723166])\n","Epoch : [33] Train loss : [0.0378536975809506] Val Score : [0.9097393418694286])\n","Epoch : [34] Train loss : [0.03817843007189887] Val Score : [0.9165787375726882])\n","Epoch : [35] Train loss : [0.0380111320742539] Val Score : [0.9165787375726882])\n","Epoch : [36] Train loss : [0.040467768375362666] Val Score : [0.9165787375726882])\n","Epoch : [37] Train loss : [0.03837887729917254] Val Score : [0.9165787375726882])\n","Epoch : [38] Train loss : [0.03797729845557894] Val Score : [0.9165787375726882])\n","Epoch : [39] Train loss : [0.037674649485519955] Val Score : [0.9165787375726882])\n","Epoch : [40] Train loss : [0.03645954706839153] Val Score : [0.9165787375726882])\n","Epoch : [41] Train loss : [0.03862748933689935] Val Score : [0.9165787375726882])\n","Epoch : [42] Train loss : [0.03620893508195877] Val Score : [0.9165787375726882])\n","Epoch : [43] Train loss : [0.03849239753825324] Val Score : [0.9165787375726882])\n","Epoch : [44] Train loss : [0.037602441651480537] Val Score : [0.9165787375726882])\n","Epoch : [45] Train loss : [0.037091809191874096] Val Score : [0.9165787375726882])\n","Epoch 00046: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch : [46] Train loss : [0.029451177322438786] Val Score : [0.9165787375726882])\n","Epoch : [47] Train loss : [0.027948563120194843] Val Score : [0.9165787375726882])\n","Epoch : [48] Train loss : [0.02885928111416953] Val Score : [0.9165787375726882])\n","Epoch : [49] Train loss : [0.028991882290158952] Val Score : [0.9165787375726882])\n","Epoch : [50] Train loss : [0.031481792352029254] Val Score : [0.9165787375726882])\n","Epoch : [51] Train loss : [0.03096762432583741] Val Score : [0.9165787375726882])\n","Epoch : [52] Train loss : [0.029899233153888156] Val Score : [0.9165787375726882])\n","Epoch : [53] Train loss : [0.02815190064055579] Val Score : [0.9165787375726882])\n","Epoch : [54] Train loss : [0.02826106228998729] Val Score : [0.9165787375726882])\n","Epoch : [55] Train loss : [0.027583362800734385] Val Score : [0.9165787375726882])\n","Epoch : [56] Train loss : [0.0261845804218735] Val Score : [0.9165787375726882])\n","Epoch 00057: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch : [57] Train loss : [0.02482778100030763] Val Score : [0.9165787375726882])\n","Epoch : [58] Train loss : [0.022997617721557617] Val Score : [0.9165787375726882])\n","Epoch : [59] Train loss : [0.02163411277745451] Val Score : [0.9165787375726882])\n","Epoch : [60] Train loss : [0.021575137440647398] Val Score : [0.9165787375726882])\n","Epoch : [61] Train loss : [0.022581814921328] Val Score : [0.9165787375726882])\n","Epoch : [62] Train loss : [0.020721291324922016] Val Score : [0.9165787375726882])\n","Epoch : [63] Train loss : [0.021897501977426664] Val Score : [0.9165787375726882])\n","Epoch : [64] Train loss : [0.023138173456702913] Val Score : [0.9165787375726882])\n","Epoch : [65] Train loss : [0.021524920261331966] Val Score : [0.9165787375726882])\n","Epoch : [66] Train loss : [0.02286621555685997] Val Score : [0.9165787375726882])\n","Epoch : [67] Train loss : [0.02171481374119009] Val Score : [0.9165787375726882])\n","Epoch 00068: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch : [68] Train loss : [0.022343397938779423] Val Score : [0.9165787375726882])\n","Epoch : [69] Train loss : [0.021898030702556883] Val Score : [0.9165787375726882])\n","Epoch : [70] Train loss : [0.019296578264662197] Val Score : [0.9165787375726882])\n","Epoch : [71] Train loss : [0.0189933410978743] Val Score : [0.9165787375726882])\n","Epoch : [72] Train loss : [0.018320118742329732] Val Score : [0.9165787375726882])\n","Epoch : [73] Train loss : [0.020109609301601137] Val Score : [0.9165787375726882])\n","Epoch : [74] Train loss : [0.01826036481985024] Val Score : [0.9165787375726882])\n","Epoch : [75] Train loss : [0.01870671007782221] Val Score : [0.9165787375726882])\n","Epoch : [76] Train loss : [0.017886093418513025] Val Score : [0.9165787375726882])\n","Epoch : [77] Train loss : [0.01941088108079774] Val Score : [0.9165787375726882])\n","Epoch : [78] Train loss : [0.018818550344024385] Val Score : [0.9165787375726882])\n","Epoch 00079: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch : [79] Train loss : [0.016276627512914792] Val Score : [0.9165787375726882])\n","Epoch : [80] Train loss : [0.016023015869515284] Val Score : [0.9165787375726882])\n","Epoch : [81] Train loss : [0.01699942403606006] Val Score : [0.9165787375726882])\n","Epoch : [82] Train loss : [0.01695286708750895] Val Score : [0.9165787375726882])\n","Epoch : [83] Train loss : [0.01612866230841194] Val Score : [0.9165787375726882])\n","Epoch : [84] Train loss : [0.015145468259496348] Val Score : [0.9165787375726882])\n","Epoch : [85] Train loss : [0.01677689142525196] Val Score : [0.9165787375726882])\n","Epoch : [86] Train loss : [0.018647747114300728] Val Score : [0.9165787375726882])\n","Epoch : [87] Train loss : [0.015823827790362493] Val Score : [0.9165787375726882])\n","Epoch : [88] Train loss : [0.016625185630151203] Val Score : [0.9165787375726882])\n","Epoch : [89] Train loss : [0.017290722711810043] Val Score : [0.9165787375726882])\n","Epoch 00090: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch : [90] Train loss : [0.016433333978056908] Val Score : [0.9165787375726882])\n","Epoch : [91] Train loss : [0.015979229472577572] Val Score : [0.9165787375726882])\n","Epoch : [92] Train loss : [0.016480695057128156] Val Score : [0.9165787375726882])\n","Epoch : [93] Train loss : [0.015991858605827605] Val Score : [0.9165787375726882])\n","Epoch : [94] Train loss : [0.01666130404919386] Val Score : [0.9165787375726882])\n","Epoch : [95] Train loss : [0.017109970695206096] Val Score : [0.9165787375726882])\n","Epoch : [96] Train loss : [0.016368990231837546] Val Score : [0.9165787375726882])\n","Epoch : [97] Train loss : [0.016461301994110857] Val Score : [0.9165787375726882])\n","Epoch : [98] Train loss : [0.015946137319718088] Val Score : [0.9165787375726882])\n","Epoch : [99] Train loss : [0.017069397228104726] Val Score : [0.9165787375726882])\n","Epoch : [100] Train loss : [0.01560701456453119] Val Score : [0.9165787375726882])\n","Epoch 00101: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch : [101] Train loss : [0.015632187681538717] Val Score : [0.9165787375726882])\n","Epoch : [102] Train loss : [0.01504687951611621] Val Score : [0.9165787375726882])\n","Epoch : [103] Train loss : [0.015585638449660369] Val Score : [0.9165787375726882])\n","Epoch : [104] Train loss : [0.015359873617334025] Val Score : [0.9165787375726882])\n","Epoch : [105] Train loss : [0.01681068180395024] Val Score : [0.9165787375726882])\n","Epoch : [106] Train loss : [0.017645251538072313] Val Score : [0.9165787375726882])\n","Epoch : [107] Train loss : [0.013946216420403548] Val Score : [0.9165787375726882])\n","Epoch : [108] Train loss : [0.014618703430252416] Val Score : [0.9165787375726882])\n","Epoch : [109] Train loss : [0.014654519302504403] Val Score : [0.9165787375726882])\n","Epoch : [110] Train loss : [0.01520951690950564] Val Score : [0.9165787375726882])\n","Epoch : [111] Train loss : [0.01493559724518231] Val Score : [0.9165787375726882])\n","Epoch 00112: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch : [112] Train loss : [0.014762026789997305] Val Score : [0.9165787375726882])\n","Epoch : [113] Train loss : [0.014525298694414752] Val Score : [0.9165787375726882])\n","Epoch : [114] Train loss : [0.014542749018541403] Val Score : [0.9165787375726882])\n","Epoch : [115] Train loss : [0.018364928529730866] Val Score : [0.9165787375726882])\n","Epoch : [116] Train loss : [0.01690608249711139] Val Score : [0.9165787375726882])\n","Epoch : [117] Train loss : [0.014417131564446859] Val Score : [0.9165787375726882])\n","Epoch : [118] Train loss : [0.013749587881777967] Val Score : [0.9165787375726882])\n","Epoch : [119] Train loss : [0.017314630693622997] Val Score : [0.9165787375726882])\n","Epoch : [120] Train loss : [0.01628820411860943] Val Score : [0.9165787375726882])\n","Epoch : [121] Train loss : [0.01694469672760793] Val Score : [0.9165787375726882])\n","Epoch : [122] Train loss : [0.014062593424958842] Val Score : [0.9165787375726882])\n","Epoch 00123: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch : [123] Train loss : [0.015545344113239221] Val Score : [0.9165787375726882])\n","Epoch : [124] Train loss : [0.016439020101513182] Val Score : [0.9165787375726882])\n","Epoch : [125] Train loss : [0.01442337395357234] Val Score : [0.9165787375726882])\n","Epoch : [126] Train loss : [0.014590136972921235] Val Score : [0.9165787375726882])\n","Epoch : [127] Train loss : [0.014839550081108297] Val Score : [0.9165787375726882])\n","Epoch : [128] Train loss : [0.01508428222898926] Val Score : [0.9165787375726882])\n","Epoch : [129] Train loss : [0.016405731971774782] Val Score : [0.9165787375726882])\n","Epoch : [130] Train loss : [0.01481276550995452] Val Score : [0.9165787375726882])\n","Epoch : [131] Train loss : [0.014861567744186946] Val Score : [0.9165787375726882])\n","Epoch : [132] Train loss : [0.014784659259021282] Val Score : [0.9165787375726882])\n","Epoch : [133] Train loss : [0.014201445238930839] Val Score : [0.9165787375726882])\n","Epoch 00134: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch : [134] Train loss : [0.016363081921424185] Val Score : [0.9165787375726882])\n","Epoch : [135] Train loss : [0.01535166786717517] Val Score : [0.9165787375726882])\n","Epoch : [136] Train loss : [0.016183098645082543] Val Score : [0.9165787375726882])\n","Epoch : [137] Train loss : [0.014069307728537492] Val Score : [0.9165787375726882])\n","Epoch : [138] Train loss : [0.014529533019023282] Val Score : [0.9165787375726882])\n","Epoch : [139] Train loss : [0.01379435948495354] Val Score : [0.9165787375726882])\n","Epoch : [140] Train loss : [0.016539966022329673] Val Score : [0.9165787375726882])\n","Epoch : [141] Train loss : [0.01357604656368494] Val Score : [0.9165787375726882])\n","Epoch : [142] Train loss : [0.0151658369494336] Val Score : [0.9165787375726882])\n","Epoch : [143] Train loss : [0.018528874032199383] Val Score : [0.9165787375726882])\n","Epoch : [144] Train loss : [0.01441663330686944] Val Score : [0.9165787375726882])\n","Epoch 00145: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch : [145] Train loss : [0.014437749183603696] Val Score : [0.9165787375726882])\n","Epoch : [146] Train loss : [0.01309340593538114] Val Score : [0.9165787375726882])\n","Epoch : [147] Train loss : [0.016262068945382322] Val Score : [0.9165787375726882])\n","Epoch : [148] Train loss : [0.015190251038542815] Val Score : [0.9165787375726882])\n","Epoch : [149] Train loss : [0.016363796378884996] Val Score : [0.9165787375726882])\n","Epoch : [150] Train loss : [0.01618584950587579] Val Score : [0.9165787375726882])\n","Epoch : [151] Train loss : [0.01564268036080258] Val Score : [0.9165787375726882])\n","Epoch : [152] Train loss : [0.015168991338993822] Val Score : [0.9165787375726882])\n","Epoch : [153] Train loss : [0.01343156277601208] Val Score : [0.9165787375726882])\n","Epoch : [154] Train loss : [0.015881579236260483] Val Score : [0.9165787375726882])\n","Epoch : [155] Train loss : [0.014184343495539256] Val Score : [0.9165787375726882])\n","Epoch 00156: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch : [156] Train loss : [0.014452339549149786] Val Score : [0.9165787375726882])\n","Epoch : [157] Train loss : [0.015687335016471998] Val Score : [0.9165787375726882])\n","Epoch : [158] Train loss : [0.013865993358194828] Val Score : [0.9165787375726882])\n","Epoch : [159] Train loss : [0.013754013260560376] Val Score : [0.9165787375726882])\n","Epoch : [160] Train loss : [0.015950331464409828] Val Score : [0.9165787375726882])\n","Epoch : [161] Train loss : [0.01405732027654137] Val Score : [0.9165787375726882])\n","Epoch : [162] Train loss : [0.014550902747682162] Val Score : [0.9165787375726882])\n","Epoch : [163] Train loss : [0.015013698887612139] Val Score : [0.9165787375726882])\n","Epoch : [164] Train loss : [0.015732595031814917] Val Score : [0.9165787375726882])\n","Epoch : [165] Train loss : [0.013516258847500597] Val Score : [0.9165787375726882])\n","Epoch : [166] Train loss : [0.015865652955004146] Val Score : [0.9165787375726882])\n","Epoch 00167: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch : [167] Train loss : [0.015359256150467055] Val Score : [0.9165787375726882])\n","Epoch : [168] Train loss : [0.017082750531179563] Val Score : [0.9165787375726882])\n","Epoch : [169] Train loss : [0.016147998294660022] Val Score : [0.9165787375726882])\n","Epoch : [170] Train loss : [0.014782198970871312] Val Score : [0.9165787375726882])\n","Epoch : [171] Train loss : [0.014636542248938764] Val Score : [0.9165787375726882])\n","Epoch : [172] Train loss : [0.015709505416452885] Val Score : [0.9165787375726882])\n","Epoch : [173] Train loss : [0.015677813041423048] Val Score : [0.9165787375726882])\n","Epoch : [174] Train loss : [0.014503740040319306] Val Score : [0.9165787375726882])\n","Epoch : [175] Train loss : [0.013495501263865404] Val Score : [0.9165787375726882])\n","Epoch : [176] Train loss : [0.016200133998479162] Val Score : [0.9165787375726882])\n","Epoch : [177] Train loss : [0.01479583206985678] Val Score : [0.9165787375726882])\n","Epoch 00178: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch : [178] Train loss : [0.014356835878321103] Val Score : [0.9165787375726882])\n","Epoch : [179] Train loss : [0.016602417853261744] Val Score : [0.9165787375726882])\n","Epoch : [180] Train loss : [0.015015366487205029] Val Score : [0.9165787375726882])\n","Epoch : [181] Train loss : [0.013606131076812744] Val Score : [0.9165787375726882])\n","Epoch : [182] Train loss : [0.013051446394196578] Val Score : [0.9165787375726882])\n","Epoch : [183] Train loss : [0.014967219371880804] Val Score : [0.9165787375726882])\n","Epoch : [184] Train loss : [0.013574072958103247] Val Score : [0.9165787375726882])\n","Epoch : [185] Train loss : [0.014964341052940913] Val Score : [0.9165787375726882])\n","Epoch : [186] Train loss : [0.016617723740637302] Val Score : [0.9165787375726882])\n","Epoch : [187] Train loss : [0.014308858795889787] Val Score : [0.9165787375726882])\n","Epoch : [188] Train loss : [0.014559404259281499] Val Score : [0.9165787375726882])\n","Epoch 00189: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch : [189] Train loss : [0.013519407649125372] Val Score : [0.9165787375726882])\n","Epoch : [190] Train loss : [0.014578476282102721] Val Score : [0.9165787375726882])\n","Epoch : [191] Train loss : [0.013989984456981932] Val Score : [0.9165787375726882])\n","Epoch : [192] Train loss : [0.014792332159621375] Val Score : [0.9165787375726882])\n","Epoch : [193] Train loss : [0.014406999173973287] Val Score : [0.9165787375726882])\n","Epoch : [194] Train loss : [0.014770872624857085] Val Score : [0.9165787375726882])\n","Epoch : [195] Train loss : [0.014331483681287085] Val Score : [0.9165787375726882])\n","Epoch : [196] Train loss : [0.014523484344993318] Val Score : [0.9165787375726882])\n","Epoch : [197] Train loss : [0.015100668450551373] Val Score : [0.9165787375726882])\n","Epoch : [198] Train loss : [0.014578059315681458] Val Score : [0.9165787375726882])\n","Epoch : [199] Train loss : [0.015419708964015757] Val Score : [0.9165787375726882])\n","Epoch 00200: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch : [200] Train loss : [0.01559011691382953] Val Score : [0.9165787375726882])\n","Epoch : [201] Train loss : [0.015549155484352793] Val Score : [0.9165787375726882])\n","Epoch : [202] Train loss : [0.014992429608745235] Val Score : [0.9165787375726882])\n","Epoch : [203] Train loss : [0.015571826403694493] Val Score : [0.9165787375726882])\n","Epoch : [204] Train loss : [0.013567075399415833] Val Score : [0.9165787375726882])\n","Epoch : [205] Train loss : [0.014855409972369671] Val Score : [0.9165787375726882])\n","Epoch : [206] Train loss : [0.01633684496794428] Val Score : [0.9165787375726882])\n","Epoch : [207] Train loss : [0.015536453574895859] Val Score : [0.9165787375726882])\n","Epoch : [208] Train loss : [0.015253680891224317] Val Score : [0.9165787375726882])\n","Epoch : [209] Train loss : [0.016916508919426372] Val Score : [0.9165787375726882])\n","Epoch : [210] Train loss : [0.014785036577710084] Val Score : [0.9165787375726882])\n","Epoch 00211: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch : [211] Train loss : [0.015017227535801274] Val Score : [0.9165787375726882])\n","Epoch : [212] Train loss : [0.014170117410165923] Val Score : [0.9165787375726882])\n","Epoch : [213] Train loss : [0.014351352384047849] Val Score : [0.9165787375726882])\n","Epoch : [214] Train loss : [0.014297784040016788] Val Score : [0.9165787375726882])\n","Epoch : [215] Train loss : [0.013818931499762195] Val Score : [0.9165787375726882])\n","Epoch : [216] Train loss : [0.014457575045526028] Val Score : [0.9165787375726882])\n","Epoch : [217] Train loss : [0.017199531197547913] Val Score : [0.9165787375726882])\n","Epoch : [218] Train loss : [0.01375593218420233] Val Score : [0.9165787375726882])\n","Epoch : [219] Train loss : [0.014640744110303265] Val Score : [0.9165787375726882])\n","Epoch : [220] Train loss : [0.01664330331342561] Val Score : [0.9165787375726882])\n","Epoch : [221] Train loss : [0.01327833772769996] Val Score : [0.9165787375726882])\n","Epoch 00222: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch : [222] Train loss : [0.016818619333207607] Val Score : [0.9165787375726882])\n","Epoch : [223] Train loss : [0.013243171918605055] Val Score : [0.9165787375726882])\n","Epoch : [224] Train loss : [0.014180853164621763] Val Score : [0.9165787375726882])\n","Epoch : [225] Train loss : [0.014653806840734822] Val Score : [0.9165787375726882])\n","Epoch : [226] Train loss : [0.014402390590735845] Val Score : [0.9165787375726882])\n","Epoch : [227] Train loss : [0.01555178833327123] Val Score : [0.9165787375726882])\n","Epoch : [228] Train loss : [0.013650399898844106] Val Score : [0.9165787375726882])\n","Epoch : [229] Train loss : [0.015554212432886873] Val Score : [0.9165787375726882])\n","Epoch : [230] Train loss : [0.01423922713313784] Val Score : [0.9165787375726882])\n","Epoch : [231] Train loss : [0.01401044281997851] Val Score : [0.9165787375726882])\n","Epoch : [232] Train loss : [0.014117774553596973] Val Score : [0.9165787375726882])\n","Epoch 00233: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch : [233] Train loss : [0.014405194936054093] Val Score : [0.9165787375726882])\n","Epoch : [234] Train loss : [0.015840158930846622] Val Score : [0.9165787375726882])\n","Epoch : [235] Train loss : [0.014211428883884634] Val Score : [0.9165787375726882])\n","Epoch : [236] Train loss : [0.015202606895140238] Val Score : [0.9165787375726882])\n","Epoch : [237] Train loss : [0.01709512315158333] Val Score : [0.9165787375726882])\n","Epoch : [238] Train loss : [0.015619938793991293] Val Score : [0.9165787375726882])\n","Epoch : [239] Train loss : [0.01589982051934515] Val Score : [0.9165787375726882])\n","Epoch : [240] Train loss : [0.013642528227397374] Val Score : [0.9165787375726882])\n","Epoch : [241] Train loss : [0.013374150464577335] Val Score : [0.9165787375726882])\n","Epoch : [242] Train loss : [0.014962285091834409] Val Score : [0.9165787375726882])\n","Epoch : [243] Train loss : [0.015539223594324929] Val Score : [0.9165787375726882])\n","Epoch 00244: reducing learning rate of group 0 to 1.9073e-08.\n","Epoch : [244] Train loss : [0.012913244909473829] Val Score : [0.9165787375726882])\n","Epoch : [245] Train loss : [0.015338357138846601] Val Score : [0.9165787375726882])\n","Epoch : [246] Train loss : [0.014792116225830146] Val Score : [0.9165787375726882])\n","Epoch : [247] Train loss : [0.01578389640365328] Val Score : [0.9165787375726882])\n","Epoch : [248] Train loss : [0.013030070944556169] Val Score : [0.9165787375726882])\n","Epoch : [249] Train loss : [0.01290489440517766] Val Score : [0.9165787375726882])\n","Epoch : [250] Train loss : [0.016534704182829176] Val Score : [0.9165787375726882])\n","Epoch : [251] Train loss : [0.013898926387940134] Val Score : [0.9165787375726882])\n","Epoch : [252] Train loss : [0.014398446838770593] Val Score : [0.9165787375726882])\n","Epoch : [253] Train loss : [0.014431265848023551] Val Score : [0.9165787375726882])\n","Epoch : [254] Train loss : [0.0162680625383343] Val Score : [0.9165787375726882])\n","Epoch : [255] Train loss : [0.014668006982122148] Val Score : [0.9165787375726882])\n","Epoch : [256] Train loss : [0.015239320030169827] Val Score : [0.9165787375726882])\n","Epoch : [257] Train loss : [0.015382318358336176] Val Score : [0.9165787375726882])\n","Epoch : [258] Train loss : [0.01633230024682624] Val Score : [0.9165787375726882])\n","Epoch : [259] Train loss : [0.014464683165507657] Val Score : [0.9165787375726882])\n","Epoch : [260] Train loss : [0.013323534013969558] Val Score : [0.9165787375726882])\n","Epoch : [261] Train loss : [0.014440064318478107] Val Score : [0.9165787375726882])\n","Epoch : [262] Train loss : [0.014580179271953446] Val Score : [0.9165787375726882])\n","Epoch : [263] Train loss : [0.015003995570753301] Val Score : [0.9165787375726882])\n","Epoch : [264] Train loss : [0.013902554554598672] Val Score : [0.9165787375726882])\n","Epoch : [265] Train loss : [0.014117062757057803] Val Score : [0.9165787375726882])\n","Epoch : [266] Train loss : [0.015382625428693635] Val Score : [0.9165787375726882])\n","Epoch : [267] Train loss : [0.013858613691159658] Val Score : [0.9165787375726882])\n","Epoch : [268] Train loss : [0.01431088921214853] Val Score : [0.9165787375726882])\n","Epoch : [269] Train loss : [0.01490746864250728] Val Score : [0.9165787375726882])\n","Epoch : [270] Train loss : [0.01656684878149203] Val Score : [0.9165787375726882])\n","Epoch : [271] Train loss : [0.014419400000146456] Val Score : [0.9165787375726882])\n","Epoch : [272] Train loss : [0.013664141430386476] Val Score : [0.9165787375726882])\n","Epoch : [273] Train loss : [0.014320533722639084] Val Score : [0.9165787375726882])\n","Epoch : [274] Train loss : [0.014741018946681703] Val Score : [0.9165787375726882])\n","Epoch : [275] Train loss : [0.014673660509288311] Val Score : [0.9165787375726882])\n","Epoch : [276] Train loss : [0.015920354053378105] Val Score : [0.9165787375726882])\n","Epoch : [277] Train loss : [0.013872724026441574] Val Score : [0.9165787375726882])\n","Epoch : [278] Train loss : [0.015004518308809825] Val Score : [0.9165787375726882])\n","Epoch : [279] Train loss : [0.01373776261295591] Val Score : [0.9165787375726882])\n","Epoch : [280] Train loss : [0.01410625342811857] Val Score : [0.9165787375726882])\n","Epoch : [281] Train loss : [0.015475408573235785] Val Score : [0.9165787375726882])\n","Epoch : [282] Train loss : [0.01509478289101805] Val Score : [0.9165787375726882])\n","Epoch : [283] Train loss : [0.01441519201866218] Val Score : [0.9165787375726882])\n","Epoch : [284] Train loss : [0.013171072650168623] Val Score : [0.9165787375726882])\n","Epoch : [285] Train loss : [0.015323131212166377] Val Score : [0.9165787375726882])\n","Epoch : [286] Train loss : [0.014480127686900752] Val Score : [0.9165787375726882])\n","Epoch : [287] Train loss : [0.01459159143269062] Val Score : [0.9165787375726882])\n","Epoch : [288] Train loss : [0.01306486182979175] Val Score : [0.9165787375726882])\n","Epoch : [289] Train loss : [0.0132804736495018] Val Score : [0.9165787375726882])\n","Epoch : [290] Train loss : [0.014345503013048853] Val Score : [0.9165787375726882])\n","Epoch : [291] Train loss : [0.015017986962837833] Val Score : [0.9165787375726882])\n","Epoch : [292] Train loss : [0.013584095851651259] Val Score : [0.9165787375726882])\n","Epoch : [293] Train loss : [0.014716151702616895] Val Score : [0.9165787375726882])\n","Epoch : [294] Train loss : [0.015340522463832582] Val Score : [0.9165787375726882])\n","Epoch : [295] Train loss : [0.01557326250310455] Val Score : [0.9165787375726882])\n","Epoch : [296] Train loss : [0.01647876269583191] Val Score : [0.9165787375726882])\n","Epoch : [297] Train loss : [0.015103113305355822] Val Score : [0.9165787375726882])\n","Epoch : [298] Train loss : [0.015762704158467904] Val Score : [0.9165787375726882])\n","Epoch : [299] Train loss : [0.016422361800713197] Val Score : [0.9165787375726882])\n","Epoch : [300] Train loss : [0.013725978322327137] Val Score : [0.9165787375726882])\n","Epoch : [301] Train loss : [0.014959833318633693] Val Score : [0.9165787375726882])\n","Epoch : [302] Train loss : [0.014433785607772214] Val Score : [0.9165787375726882])\n","Epoch : [303] Train loss : [0.014789483110819544] Val Score : [0.9165787375726882])\n","Epoch : [304] Train loss : [0.0143486564712865] Val Score : [0.9165787375726882])\n","Epoch : [305] Train loss : [0.01409733628055879] Val Score : [0.9165787375726882])\n","Epoch : [306] Train loss : [0.01477178159568991] Val Score : [0.9165787375726882])\n","Epoch : [307] Train loss : [0.015641119863305773] Val Score : [0.9165787375726882])\n","Epoch : [308] Train loss : [0.014149550082428115] Val Score : [0.9165787375726882])\n","Epoch : [309] Train loss : [0.015190990375620978] Val Score : [0.9165787375726882])\n","Epoch : [310] Train loss : [0.01490054971405438] Val Score : [0.9165787375726882])\n","Epoch : [311] Train loss : [0.01613415591418743] Val Score : [0.9165787375726882])\n","Epoch : [312] Train loss : [0.01578129961022309] Val Score : [0.9165787375726882])\n","Epoch : [313] Train loss : [0.014442486954586846] Val Score : [0.9165787375726882])\n","Epoch : [314] Train loss : [0.01637119081403528] Val Score : [0.9165787375726882])\n","Epoch : [315] Train loss : [0.014559076832873481] Val Score : [0.9165787375726882])\n","Epoch : [316] Train loss : [0.01288860517420939] Val Score : [0.9165787375726882])\n","Epoch : [317] Train loss : [0.015142284333705902] Val Score : [0.9165787375726882])\n","Epoch : [318] Train loss : [0.016712147343371595] Val Score : [0.9165787375726882])\n","Epoch : [319] Train loss : [0.014620499552360602] Val Score : [0.9165787375726882])\n","Epoch : [320] Train loss : [0.014806148995246207] Val Score : [0.9165787375726882])\n","Epoch : [321] Train loss : [0.013086163438856602] Val Score : [0.9165787375726882])\n","Epoch : [322] Train loss : [0.012688392773270607] Val Score : [0.9165787375726882])\n","Epoch : [323] Train loss : [0.01545123290270567] Val Score : [0.9165787375726882])\n","Epoch : [324] Train loss : [0.015295221071158136] Val Score : [0.9165787375726882])\n","Epoch : [325] Train loss : [0.014557986387184687] Val Score : [0.9165787375726882])\n","Epoch : [326] Train loss : [0.016267673378544196] Val Score : [0.9165787375726882])\n","Epoch : [327] Train loss : [0.013414851655917508] Val Score : [0.9165787375726882])\n","Epoch : [328] Train loss : [0.013338593233908926] Val Score : [0.9165787375726882])\n","Epoch : [329] Train loss : [0.015739405527710915] Val Score : [0.9165787375726882])\n","Epoch : [330] Train loss : [0.01647262355046613] Val Score : [0.9165787375726882])\n","Epoch : [331] Train loss : [0.014844970910676889] Val Score : [0.9165787375726882])\n","Epoch : [332] Train loss : [0.016090422868728638] Val Score : [0.9165787375726882])\n","Epoch : [333] Train loss : [0.015394568044160093] Val Score : [0.9165787375726882])\n","Epoch : [334] Train loss : [0.015915215547595705] Val Score : [0.9165787375726882])\n","Epoch : [335] Train loss : [0.014146306685038976] Val Score : [0.9165787375726882])\n","Epoch : [336] Train loss : [0.014733787093843733] Val Score : [0.9165787375726882])\n","Epoch : [337] Train loss : [0.016080665002976145] Val Score : [0.9165787375726882])\n","Epoch : [338] Train loss : [0.014245193717735154] Val Score : [0.9165787375726882])\n","Epoch : [339] Train loss : [0.017207583678620204] Val Score : [0.9165787375726882])\n","Epoch : [340] Train loss : [0.015512820732380663] Val Score : [0.9165787375726882])\n","Epoch : [341] Train loss : [0.01583688799291849] Val Score : [0.9165787375726882])\n","Epoch : [342] Train loss : [0.01504177919455937] Val Score : [0.9165787375726882])\n","Epoch : [343] Train loss : [0.014753420571131366] Val Score : [0.9165787375726882])\n","Epoch : [344] Train loss : [0.015383894688316755] Val Score : [0.9165787375726882])\n","Epoch : [345] Train loss : [0.014956785898123468] Val Score : [0.9165787375726882])\n","Epoch : [346] Train loss : [0.013738507138831275] Val Score : [0.9165787375726882])\n","Epoch : [347] Train loss : [0.01578858880592244] Val Score : [0.9165787375726882])\n","Epoch : [348] Train loss : [0.01660260438386883] Val Score : [0.9165787375726882])\n","Epoch : [349] Train loss : [0.01806750095316342] Val Score : [0.9165787375726882])\n","Epoch : [350] Train loss : [0.015930795909038613] Val Score : [0.9165787375726882])\n","Epoch : [351] Train loss : [0.015230860295040267] Val Score : [0.9165787375726882])\n","Epoch : [352] Train loss : [0.014518976078501769] Val Score : [0.9165787375726882])\n","Epoch : [353] Train loss : [0.014978977984615735] Val Score : [0.9165787375726882])\n","Epoch : [354] Train loss : [0.015867688693106174] Val Score : [0.9165787375726882])\n","Epoch : [355] Train loss : [0.01609563747686999] Val Score : [0.9165787375726882])\n","Epoch : [356] Train loss : [0.015052860735782556] Val Score : [0.9165787375726882])\n","Epoch : [357] Train loss : [0.016198762293372835] Val Score : [0.9165787375726882])\n","Epoch : [358] Train loss : [0.015014049730130605] Val Score : [0.9165787375726882])\n","Epoch : [359] Train loss : [0.015311580417411668] Val Score : [0.9165787375726882])\n","Epoch : [360] Train loss : [0.01460902246513537] Val Score : [0.9165787375726882])\n","Epoch : [361] Train loss : [0.015462895855307579] Val Score : [0.9165787375726882])\n","Epoch : [362] Train loss : [0.015030705503055028] Val Score : [0.9165787375726882])\n","Epoch : [363] Train loss : [0.014385604964835303] Val Score : [0.9165787375726882])\n","Epoch : [364] Train loss : [0.015042308318827833] Val Score : [0.9165787375726882])\n","Epoch : [365] Train loss : [0.014981287797646863] Val Score : [0.9165787375726882])\n","Epoch : [366] Train loss : [0.01584674245012658] Val Score : [0.9165787375726882])\n","Epoch : [367] Train loss : [0.01548790093511343] Val Score : [0.9165787375726882])\n","Epoch : [368] Train loss : [0.014504904991814069] Val Score : [0.9165787375726882])\n","Epoch : [369] Train loss : [0.015677223381187235] Val Score : [0.9165787375726882])\n","Epoch : [370] Train loss : [0.014577674945550305] Val Score : [0.9165787375726882])\n","Epoch : [371] Train loss : [0.013664782180317811] Val Score : [0.9165787375726882])\n","Epoch : [372] Train loss : [0.014127106804932867] Val Score : [0.9165787375726882])\n","Epoch : [373] Train loss : [0.013354602535920483] Val Score : [0.9165787375726882])\n","Epoch : [374] Train loss : [0.01495349540242127] Val Score : [0.9165787375726882])\n","Epoch : [375] Train loss : [0.015024846020553793] Val Score : [0.9165787375726882])\n","Epoch : [376] Train loss : [0.015928886165576323] Val Score : [0.9165787375726882])\n","Epoch : [377] Train loss : [0.0143552426514881] Val Score : [0.9165787375726882])\n","Epoch : [378] Train loss : [0.015123932090188776] Val Score : [0.9165787375726882])\n","Epoch : [379] Train loss : [0.014723985588976316] Val Score : [0.9165787375726882])\n","Epoch : [380] Train loss : [0.0159265666401812] Val Score : [0.9165787375726882])\n","Epoch : [381] Train loss : [0.014829188718327455] Val Score : [0.9165787375726882])\n","Epoch : [382] Train loss : [0.016824821010231972] Val Score : [0.9165787375726882])\n","Epoch : [383] Train loss : [0.016825327250574316] Val Score : [0.9165787375726882])\n","Epoch : [384] Train loss : [0.015237235331109591] Val Score : [0.9165787375726882])\n","Epoch : [385] Train loss : [0.014167809459779943] Val Score : [0.9165787375726882])\n","Epoch : [386] Train loss : [0.015621086715587549] Val Score : [0.9165787375726882])\n","Epoch : [387] Train loss : [0.015566716369773661] Val Score : [0.9165787375726882])\n","Epoch : [388] Train loss : [0.014026038614766938] Val Score : [0.9165787375726882])\n","Epoch : [389] Train loss : [0.015293164710913385] Val Score : [0.9165787375726882])\n","Epoch : [390] Train loss : [0.015930193609425] Val Score : [0.9165787375726882])\n","Epoch : [391] Train loss : [0.015982565470039845] Val Score : [0.9165787375726882])\n","Epoch : [392] Train loss : [0.015568559989333153] Val Score : [0.9165787375726882])\n","Epoch : [393] Train loss : [0.013883332455796855] Val Score : [0.9165787375726882])\n","Epoch : [394] Train loss : [0.015173249478851045] Val Score : [0.9165787375726882])\n","Epoch : [395] Train loss : [0.014883557600634438] Val Score : [0.9165787375726882])\n","Epoch : [396] Train loss : [0.015976362196462496] Val Score : [0.9165787375726882])\n","Epoch : [397] Train loss : [0.014035035323883806] Val Score : [0.9165787375726882])\n","Epoch : [398] Train loss : [0.014880138316324778] Val Score : [0.9165787375726882])\n","Epoch : [399] Train loss : [0.015186629258096218] Val Score : [0.9165787375726882])\n"]}],"source":["model = nn.DataParallel(AutoEncoder())\n","model.eval()\n","\n","# optim 패키지를 사용하여 모델의 가중치를 갱신할 optimizer를 정의합니다.\n","optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n","# 학습률 개선 scheduler, patience번 정체되면 학습률 factor와 곱한다. \n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n","\n","trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n","trainer.fit()"]},{"cell_type":"markdown","source":["### train 데이터를 예측"],"metadata":{"id":"HudNXB80eDDx"}},{"cell_type":"code","source":["# 학습된 내용 불러오기\n","model = AutoEncoder()\n","model.load_state_dict(torch.load('./best_model.pth'))\n","model = nn.DataParallel(model)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E5jCXae_eKy4","executionInfo":{"status":"ok","timestamp":1658823127334,"user_tz":-540,"elapsed":365,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"beef5eb9-deb3-4263-80ee-10c0f44a96a2"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataParallel(\n","  (module): AutoEncoder(\n","    (Encoder): Sequential(\n","      (0): Linear(in_features=30, out_features=64, bias=True)\n","      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): PReLU(num_parameters=1)\n","      (3): Linear(in_features=64, out_features=128, bias=True)\n","      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): PReLU(num_parameters=1)\n","    )\n","    (Decoder): Sequential(\n","      (0): Linear(in_features=128, out_features=64, bias=True)\n","      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): PReLU(num_parameters=1)\n","      (3): Linear(in_features=64, out_features=30, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["train_loader2 = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=2)"],"metadata":{"id":"8ZE5Ll2aeSDC","executionInfo":{"status":"ok","timestamp":1658823128814,"user_tz":-540,"elapsed":4,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def prediction(model, thr, test_loader, device):\n","    model.to(device)\n","    model.eval()\n","    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","    pred = []\n","    with torch.no_grad():\n","        for x in iter(test_loader):\n","            x = x.float().to(device)\n","            \n","            _x = model(x)\n","            \n","            diff = cos(x, _x).cpu().tolist()\n","            batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n","            pred += batch_pred\n","    return pred"],"metadata":{"id":"zFK4FmmXeha4","executionInfo":{"status":"ok","timestamp":1658823132487,"user_tz":-540,"elapsed":315,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["train_df2 = train_df\n","preds = prediction(model,0.95,train_loader2,device)"],"metadata":{"id":"54rq9_YDeiDA","executionInfo":{"status":"ok","timestamp":1658823135010,"user_tz":-540,"elapsed":820,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["train_df2['Class'] = preds"],"metadata":{"id":"Su36pZ3Dew1f","executionInfo":{"status":"ok","timestamp":1658823136584,"user_tz":-540,"elapsed":4,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["train_df2_normal = train_df2[train_df['Class']==0]"],"metadata":{"id":"qAwKO0x5fe5D","executionInfo":{"status":"ok","timestamp":1658823138118,"user_tz":-540,"elapsed":4,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["train_df2_normal = train_df2_normal.drop(columns=['Class'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":327},"id":"ilsxkLRie5ni","executionInfo":{"status":"error","timestamp":1658823275612,"user_tz":-540,"elapsed":424,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"ece21c48-cf61-47ae-890c-92db69c32b17"},"execution_count":24,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-41d465e2b5c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df2_normal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df2_normal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4913\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4914\u001b[0m         )\n\u001b[1;32m   4915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['Class'] not found in axis\""]}]},{"cell_type":"markdown","source":["### 예측한 train_df2 로 모델 다시 구성"],"metadata":{"id":"oycJjBC0fL8r"}},{"cell_type":"code","source":["train_dataset2 = MyDataset(df=train_df2_normal, eval_mode=False)\n","train_loader2 = DataLoader(train_dataset2, batch_size=BS, shuffle=True, num_workers=2)"],"metadata":{"id":"Ei8YtWB9fYio","executionInfo":{"status":"ok","timestamp":1658823283838,"user_tz":-540,"elapsed":2,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["class Trainer():\n","    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.scheduler = scheduler\n","        self.device = device\n","        # Loss Function\n","        self.criterion = nn.L1Loss().to(self.device)\n","        \n","    def fit(self, ):\n","        self.model.to(self.device)\n","        best_score = 0\n","        for epoch in range(EPOCHS):\n","            self.model.train()\n","            train_loss = []\n","            for x in iter(self.train_loader):\n","                x = x.float().to(self.device)\n","                # 역전파 단계 전에, optimizer 객체를 사용하여 (모델의 학습 가능한 가중치인) 갱신할\n","                # 변수들에 대한 모든 변화도(gradient)를 0으로 만듭니다. 이렇게 하는 이유는 기본적으로 \n","                # .backward()를 호출할 때마다 변화도가 버퍼(buffer)에 (덮어쓰지 않고) 누적되기\n","                # 때문입니다. 더 자세한 내용은 torch.autograd.backward에 대한 문서를 참조하세요.\n","                self.optimizer.zero_grad()\n","\n","                # AutoEncoder 통과한 예측값\n","                _x = self.model(x)\n","                loss = self.criterion(x, _x)\n","\n","                # 역전파 단계: 모델의 매개변수들에 대한 손실의 변화도를 계산합니다.\n","                loss.backward()\n","                # optimizer의 step 함수를 호출하면 매개변수가 갱신됩니다.\n","                self.optimizer.step()\n","\n","                train_loss.append(loss.item())\n","\n","            score = self.validation(self.model, 0.95)\n","            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n","\n","            if self.scheduler is not None:\n","                self.scheduler.step(score)\n","\n","            if best_score < score:\n","                best_score = score\n","                torch.save(model.module.state_dict(), './best_model2.pth', _use_new_zipfile_serialization=False)\n","    \n","    def validation(self, eval_model, thr):\n","        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","        #  model.eval()는 이런 layer들의 동작을 inference(eval) mode로 바꿔준다는 목적\n","        eval_model.eval()\n","        pred = []\n","        true = []\n","        # torch.no_grad()의 주된 목적은 autograd(자동으로 gradient를 트래킹)를 끔으로써 메모리 사용량을 줄이고 연산 속도를 높히기 위함\n","        with torch.no_grad():\n","            for x, y in iter(self.val_loader):\n","                x = x.float().to(self.device)\n","\n","                _x = self.model(x)\n","                diff = cos(x, _x).cpu().tolist()\n","                #유사도 0.95보다 작은것은 이상거래 1, 아닌 것은 정상거래 0\n","                batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n","                pred += batch_pred\n","                true += y.tolist()\n","\n","        return f1_score(true, pred, average='macro')"],"metadata":{"id":"duNXoMevfu1e","executionInfo":{"status":"ok","timestamp":1658823286478,"user_tz":-540,"elapsed":365,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["model2 = nn.DataParallel(AutoEncoder())\n","model2.eval()\n","\n","# optim 패키지를 사용하여 모델의 가중치를 갱신할 optimizer를 정의합니다.\n","optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n","# 학습률 개선 scheduler, patience번 정체되면 학습률 factor와 곱한다. \n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n","\n","trainer2 = Trainer(model, optimizer, train_loader2, val_loader, scheduler, device)\n","trainer2.fit()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CeBzbbaUfSBU","executionInfo":{"status":"ok","timestamp":1658823935395,"user_tz":-540,"elapsed":638360,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"2566a36e-c494-432a-da79-66da5a12b75c"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : [0] Train loss : [0.12345490444983755] Val Score : [0.9165787375726882])\n","Epoch : [1] Train loss : [0.07479494969759669] Val Score : [0.9165787375726882])\n","Epoch : [2] Train loss : [0.05588579124638012] Val Score : [0.9165787375726882])\n","Epoch : [3] Train loss : [0.04396542268139975] Val Score : [0.9165787375726882])\n","Epoch : [4] Train loss : [0.04076072626880237] Val Score : [0.9165787375726882])\n","Epoch : [5] Train loss : [0.037180643528699875] Val Score : [0.9165787375726882])\n","Epoch : [6] Train loss : [0.03802211316568511] Val Score : [0.9165787375726882])\n","Epoch : [7] Train loss : [0.036426473941121786] Val Score : [0.9165787375726882])\n","Epoch : [8] Train loss : [0.04184137497629438] Val Score : [0.9165787375726882])\n","Epoch : [9] Train loss : [0.03848288793648992] Val Score : [0.9165787375726882])\n","Epoch : [10] Train loss : [0.037617764834846766] Val Score : [0.9165787375726882])\n","Epoch : [11] Train loss : [0.035705599401678355] Val Score : [0.9165787375726882])\n","Epoch 00012: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch : [12] Train loss : [0.030867808631488254] Val Score : [0.9165787375726882])\n","Epoch : [13] Train loss : [0.0275558094893183] Val Score : [0.9165787375726882])\n","Epoch : [14] Train loss : [0.028889484703540802] Val Score : [0.9165787375726882])\n","Epoch : [15] Train loss : [0.027992544695734978] Val Score : [0.9165787375726882])\n","Epoch : [16] Train loss : [0.030510532004492625] Val Score : [0.9165787375726882])\n","Epoch : [17] Train loss : [0.030453501269221306] Val Score : [0.9165787375726882])\n","Epoch : [18] Train loss : [0.02887553003217493] Val Score : [0.9165787375726882])\n","Epoch : [19] Train loss : [0.02970110039625849] Val Score : [0.9165787375726882])\n","Epoch : [20] Train loss : [0.027432360287223543] Val Score : [0.9165787375726882])\n","Epoch : [21] Train loss : [0.027723027925406183] Val Score : [0.9165787375726882])\n","Epoch : [22] Train loss : [0.027620901486703327] Val Score : [0.9165787375726882])\n","Epoch 00023: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch : [23] Train loss : [0.025340373228703226] Val Score : [0.9165787375726882])\n","Epoch : [24] Train loss : [0.02438802005989211] Val Score : [0.9165787375726882])\n","Epoch : [25] Train loss : [0.022415410727262497] Val Score : [0.9165787375726882])\n","Epoch : [26] Train loss : [0.02135708475751536] Val Score : [0.9165787375726882])\n","Epoch : [27] Train loss : [0.023103907704353333] Val Score : [0.9165787375726882])\n","Epoch : [28] Train loss : [0.0243154303835971] Val Score : [0.9165787375726882])\n","Epoch : [29] Train loss : [0.02291850053838321] Val Score : [0.9165787375726882])\n","Epoch : [30] Train loss : [0.022786952022995268] Val Score : [0.9165787375726882])\n","Epoch : [31] Train loss : [0.021028568169900348] Val Score : [0.9165787375726882])\n","Epoch : [32] Train loss : [0.021814917347260883] Val Score : [0.9165787375726882])\n","Epoch : [33] Train loss : [0.0222944085087095] Val Score : [0.9165787375726882])\n","Epoch 00034: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch : [34] Train loss : [0.023376632215721265] Val Score : [0.9165787375726882])\n","Epoch : [35] Train loss : [0.019151522644928524] Val Score : [0.9165787375726882])\n","Epoch : [36] Train loss : [0.020222296938300133] Val Score : [0.9165787375726882])\n","Epoch : [37] Train loss : [0.019948430359363556] Val Score : [0.9165787375726882])\n","Epoch : [38] Train loss : [0.017827160257313932] Val Score : [0.9165787375726882])\n","Epoch : [39] Train loss : [0.018700866560850824] Val Score : [0.9165787375726882])\n","Epoch : [40] Train loss : [0.01932030969432422] Val Score : [0.9165787375726882])\n","Epoch : [41] Train loss : [0.018570536614528725] Val Score : [0.9165787375726882])\n","Epoch : [42] Train loss : [0.01830953479345356] Val Score : [0.9165787375726882])\n","Epoch : [43] Train loss : [0.017700571566820145] Val Score : [0.9165787375726882])\n","Epoch : [44] Train loss : [0.01851281723273652] Val Score : [0.9165787375726882])\n","Epoch 00045: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch : [45] Train loss : [0.01728575663375003] Val Score : [0.9165787375726882])\n","Epoch : [46] Train loss : [0.017895663556243693] Val Score : [0.9165787375726882])\n","Epoch : [47] Train loss : [0.018017746774213656] Val Score : [0.9165787375726882])\n","Epoch : [48] Train loss : [0.02141904485012804] Val Score : [0.9165787375726882])\n","Epoch : [49] Train loss : [0.017473276438457624] Val Score : [0.9165787375726882])\n","Epoch : [50] Train loss : [0.017536842663373266] Val Score : [0.9165787375726882])\n","Epoch : [51] Train loss : [0.016292861130620753] Val Score : [0.9165787375726882])\n","Epoch : [52] Train loss : [0.016568874275045737] Val Score : [0.9165787375726882])\n","Epoch : [53] Train loss : [0.01572499450828348] Val Score : [0.9165787375726882])\n","Epoch : [54] Train loss : [0.015364052461726325] Val Score : [0.9165787375726882])\n","Epoch : [55] Train loss : [0.017570102587342262] Val Score : [0.9165787375726882])\n","Epoch 00056: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch : [56] Train loss : [0.01729716932667153] Val Score : [0.9165787375726882])\n","Epoch : [57] Train loss : [0.015731526405683587] Val Score : [0.9165787375726882])\n","Epoch : [58] Train loss : [0.017418517731130123] Val Score : [0.9165787375726882])\n","Epoch : [59] Train loss : [0.015149180378232683] Val Score : [0.9165787375726882])\n","Epoch : [60] Train loss : [0.01816421507724694] Val Score : [0.9165787375726882])\n","Epoch : [61] Train loss : [0.016014046567891325] Val Score : [0.9165787375726882])\n","Epoch : [62] Train loss : [0.016139459796249866] Val Score : [0.9165787375726882])\n","Epoch : [63] Train loss : [0.016762790536241873] Val Score : [0.9165787375726882])\n","Epoch : [64] Train loss : [0.014610496615724904] Val Score : [0.9165787375726882])\n","Epoch : [65] Train loss : [0.01482690844152655] Val Score : [0.9165787375726882])\n","Epoch : [66] Train loss : [0.015386991069785185] Val Score : [0.9165787375726882])\n","Epoch 00067: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch : [67] Train loss : [0.01525212824344635] Val Score : [0.9165787375726882])\n","Epoch : [68] Train loss : [0.01464540365019015] Val Score : [0.9165787375726882])\n","Epoch : [69] Train loss : [0.015276367776095867] Val Score : [0.9165787375726882])\n","Epoch : [70] Train loss : [0.0153219091839024] Val Score : [0.9165787375726882])\n","Epoch : [71] Train loss : [0.014548557278301035] Val Score : [0.9165787375726882])\n","Epoch : [72] Train loss : [0.014368142267423016] Val Score : [0.9165787375726882])\n","Epoch : [73] Train loss : [0.017187452475939478] Val Score : [0.9165787375726882])\n","Epoch : [74] Train loss : [0.015493873772876603] Val Score : [0.9165787375726882])\n","Epoch : [75] Train loss : [0.015271734579333238] Val Score : [0.9165787375726882])\n","Epoch : [76] Train loss : [0.016105730352657183] Val Score : [0.9165787375726882])\n","Epoch : [77] Train loss : [0.015599889680743217] Val Score : [0.9165787375726882])\n","Epoch 00078: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch : [78] Train loss : [0.016750533932021687] Val Score : [0.9165787375726882])\n","Epoch : [79] Train loss : [0.013659334076302392] Val Score : [0.9165787375726882])\n","Epoch : [80] Train loss : [0.014562496915459633] Val Score : [0.9165787375726882])\n","Epoch : [81] Train loss : [0.016762624760823592] Val Score : [0.9165787375726882])\n","Epoch : [82] Train loss : [0.014674689620733261] Val Score : [0.9165787375726882])\n","Epoch : [83] Train loss : [0.015990054767046655] Val Score : [0.9165787375726882])\n","Epoch : [84] Train loss : [0.01447244267910719] Val Score : [0.9165787375726882])\n","Epoch : [85] Train loss : [0.015739387965628078] Val Score : [0.9165787375726882])\n","Epoch : [86] Train loss : [0.015646586726818765] Val Score : [0.9165787375726882])\n","Epoch : [87] Train loss : [0.01467980830264943] Val Score : [0.9165787375726882])\n","Epoch : [88] Train loss : [0.016985959905598844] Val Score : [0.9165787375726882])\n","Epoch 00089: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch : [89] Train loss : [0.015845375933817456] Val Score : [0.9165787375726882])\n","Epoch : [90] Train loss : [0.015292319336107798] Val Score : [0.9165787375726882])\n","Epoch : [91] Train loss : [0.01572893200708287] Val Score : [0.9165787375726882])\n","Epoch : [92] Train loss : [0.015762264175074443] Val Score : [0.9165787375726882])\n","Epoch : [93] Train loss : [0.015421937219798565] Val Score : [0.9165787375726882])\n","Epoch : [94] Train loss : [0.0161996672728232] Val Score : [0.9165787375726882])\n","Epoch : [95] Train loss : [0.016226524354091713] Val Score : [0.9165787375726882])\n","Epoch : [96] Train loss : [0.016184662335685322] Val Score : [0.9165787375726882])\n","Epoch : [97] Train loss : [0.017649490918431963] Val Score : [0.9165787375726882])\n","Epoch : [98] Train loss : [0.015022496559790202] Val Score : [0.9165787375726882])\n","Epoch : [99] Train loss : [0.013685532845556736] Val Score : [0.9165787375726882])\n","Epoch 00100: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch : [100] Train loss : [0.014242922221975667] Val Score : [0.9165787375726882])\n","Epoch : [101] Train loss : [0.016675596391516074] Val Score : [0.9165787375726882])\n","Epoch : [102] Train loss : [0.016448872962168286] Val Score : [0.9165787375726882])\n","Epoch : [103] Train loss : [0.014641029627195426] Val Score : [0.9165787375726882])\n","Epoch : [104] Train loss : [0.016586411079125746] Val Score : [0.9165787375726882])\n","Epoch : [105] Train loss : [0.014380709135106631] Val Score : [0.9165787375726882])\n","Epoch : [106] Train loss : [0.016599047662956373] Val Score : [0.9165787375726882])\n","Epoch : [107] Train loss : [0.016187321128589765] Val Score : [0.9165787375726882])\n","Epoch : [108] Train loss : [0.014497665954487664] Val Score : [0.9165787375726882])\n","Epoch : [109] Train loss : [0.01796044795108693] Val Score : [0.9165787375726882])\n","Epoch : [110] Train loss : [0.014919051368321692] Val Score : [0.9165787375726882])\n","Epoch 00111: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch : [111] Train loss : [0.016102825424500873] Val Score : [0.9165787375726882])\n","Epoch : [112] Train loss : [0.014397954967405115] Val Score : [0.9165787375726882])\n","Epoch : [113] Train loss : [0.016435979067214897] Val Score : [0.9165787375726882])\n","Epoch : [114] Train loss : [0.013796980625816755] Val Score : [0.9165787375726882])\n","Epoch : [115] Train loss : [0.015576399064489774] Val Score : [0.9165787375726882])\n","Epoch : [116] Train loss : [0.01721666580332177] Val Score : [0.9165787375726882])\n","Epoch : [117] Train loss : [0.01519237897757973] Val Score : [0.9165787375726882])\n","Epoch : [118] Train loss : [0.016038234744753157] Val Score : [0.9165787375726882])\n","Epoch : [119] Train loss : [0.0156921333234225] Val Score : [0.9165787375726882])\n","Epoch : [120] Train loss : [0.01487298815378121] Val Score : [0.9165787375726882])\n","Epoch : [121] Train loss : [0.01657917776278087] Val Score : [0.9165787375726882])\n","Epoch 00122: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch : [122] Train loss : [0.01435433461197785] Val Score : [0.9165787375726882])\n","Epoch : [123] Train loss : [0.015571522127304758] Val Score : [0.9165787375726882])\n","Epoch : [124] Train loss : [0.01487222925892898] Val Score : [0.9165787375726882])\n","Epoch : [125] Train loss : [0.016332675436777726] Val Score : [0.9165787375726882])\n","Epoch : [126] Train loss : [0.014107148429112775] Val Score : [0.9165787375726882])\n","Epoch : [127] Train loss : [0.01593625931335347] Val Score : [0.9165787375726882])\n","Epoch : [128] Train loss : [0.015148327818938665] Val Score : [0.9165787375726882])\n","Epoch : [129] Train loss : [0.01618877545531307] Val Score : [0.9165787375726882])\n","Epoch : [130] Train loss : [0.014816625975072384] Val Score : [0.9165787375726882])\n","Epoch : [131] Train loss : [0.016497498910341944] Val Score : [0.9165787375726882])\n","Epoch : [132] Train loss : [0.014992844446429185] Val Score : [0.9165787375726882])\n","Epoch 00133: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch : [133] Train loss : [0.01679318185363497] Val Score : [0.9165787375726882])\n","Epoch : [134] Train loss : [0.014927185672734464] Val Score : [0.9165787375726882])\n","Epoch : [135] Train loss : [0.016571821245763983] Val Score : [0.9165787375726882])\n","Epoch : [136] Train loss : [0.017007695777075633] Val Score : [0.9165787375726882])\n","Epoch : [137] Train loss : [0.015042702268276895] Val Score : [0.9165787375726882])\n","Epoch : [138] Train loss : [0.014745194065783705] Val Score : [0.9165787375726882])\n","Epoch : [139] Train loss : [0.015441515616008214] Val Score : [0.9165787375726882])\n","Epoch : [140] Train loss : [0.015982603255127157] Val Score : [0.9165787375726882])\n","Epoch : [141] Train loss : [0.015486521912472588] Val Score : [0.9165787375726882])\n","Epoch : [142] Train loss : [0.014603808389178343] Val Score : [0.9165787375726882])\n","Epoch : [143] Train loss : [0.014774803737444537] Val Score : [0.9165787375726882])\n","Epoch 00144: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch : [144] Train loss : [0.015923509640353068] Val Score : [0.9165787375726882])\n","Epoch : [145] Train loss : [0.01748485503984349] Val Score : [0.9165787375726882])\n","Epoch : [146] Train loss : [0.013752379188580173] Val Score : [0.9165787375726882])\n","Epoch : [147] Train loss : [0.01638789608010224] Val Score : [0.9165787375726882])\n","Epoch : [148] Train loss : [0.015016082009034497] Val Score : [0.9165787375726882])\n","Epoch : [149] Train loss : [0.015189531525330884] Val Score : [0.9165787375726882])\n","Epoch : [150] Train loss : [0.016587485958422934] Val Score : [0.9165787375726882])\n","Epoch : [151] Train loss : [0.01591920865965741] Val Score : [0.9165787375726882])\n","Epoch : [152] Train loss : [0.015641771656061922] Val Score : [0.9165787375726882])\n","Epoch : [153] Train loss : [0.01869021781853267] Val Score : [0.9165787375726882])\n","Epoch : [154] Train loss : [0.015018599240907602] Val Score : [0.9165787375726882])\n","Epoch 00155: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch : [155] Train loss : [0.015213456537042345] Val Score : [0.9165787375726882])\n","Epoch : [156] Train loss : [0.01562342539961849] Val Score : [0.9165787375726882])\n","Epoch : [157] Train loss : [0.014911272030855929] Val Score : [0.9165787375726882])\n","Epoch : [158] Train loss : [0.015808640313999995] Val Score : [0.9165787375726882])\n","Epoch : [159] Train loss : [0.0162345664575696] Val Score : [0.9165787375726882])\n","Epoch : [160] Train loss : [0.014108381234109402] Val Score : [0.9165787375726882])\n","Epoch : [161] Train loss : [0.01725067464368684] Val Score : [0.9165787375726882])\n","Epoch : [162] Train loss : [0.014045513235032558] Val Score : [0.9165787375726882])\n","Epoch : [163] Train loss : [0.015626036695071628] Val Score : [0.9165787375726882])\n","Epoch : [164] Train loss : [0.0175730310646551] Val Score : [0.9165787375726882])\n","Epoch : [165] Train loss : [0.013521214947104454] Val Score : [0.9165787375726882])\n","Epoch 00166: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch : [166] Train loss : [0.01636830304882356] Val Score : [0.9165787375726882])\n","Epoch : [167] Train loss : [0.01521933770605496] Val Score : [0.9165787375726882])\n","Epoch : [168] Train loss : [0.016925702403698648] Val Score : [0.9165787375726882])\n","Epoch : [169] Train loss : [0.014447113499045372] Val Score : [0.9165787375726882])\n","Epoch : [170] Train loss : [0.016074106629405702] Val Score : [0.9165787375726882])\n","Epoch : [171] Train loss : [0.013915964402258396] Val Score : [0.9165787375726882])\n","Epoch : [172] Train loss : [0.014120599920196193] Val Score : [0.9165787375726882])\n","Epoch : [173] Train loss : [0.014340113050171308] Val Score : [0.9165787375726882])\n","Epoch : [174] Train loss : [0.016179025705371584] Val Score : [0.9165787375726882])\n","Epoch : [175] Train loss : [0.014854159871382373] Val Score : [0.9165787375726882])\n","Epoch : [176] Train loss : [0.015032062706138407] Val Score : [0.9165787375726882])\n","Epoch 00177: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch : [177] Train loss : [0.016661460112248148] Val Score : [0.9165787375726882])\n","Epoch : [178] Train loss : [0.015284784138202667] Val Score : [0.9165787375726882])\n","Epoch : [179] Train loss : [0.014513310178049974] Val Score : [0.9165787375726882])\n","Epoch : [180] Train loss : [0.015521196648478508] Val Score : [0.9165787375726882])\n","Epoch : [181] Train loss : [0.013783273021025317] Val Score : [0.9165787375726882])\n","Epoch : [182] Train loss : [0.015238038929445403] Val Score : [0.9165787375726882])\n","Epoch : [183] Train loss : [0.014576540195516177] Val Score : [0.9165787375726882])\n","Epoch : [184] Train loss : [0.016342081129550934] Val Score : [0.9165787375726882])\n","Epoch : [185] Train loss : [0.01601222263915198] Val Score : [0.9165787375726882])\n","Epoch : [186] Train loss : [0.015976425925535814] Val Score : [0.9165787375726882])\n","Epoch : [187] Train loss : [0.014220476682697023] Val Score : [0.9165787375726882])\n","Epoch 00188: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch : [188] Train loss : [0.013911958384726728] Val Score : [0.9165787375726882])\n","Epoch : [189] Train loss : [0.015369336919060774] Val Score : [0.9165787375726882])\n","Epoch : [190] Train loss : [0.015061213501862116] Val Score : [0.9165787375726882])\n","Epoch : [191] Train loss : [0.014951208207224096] Val Score : [0.9165787375726882])\n","Epoch : [192] Train loss : [0.0161255325323769] Val Score : [0.9165787375726882])\n","Epoch : [193] Train loss : [0.015299881542367595] Val Score : [0.9165787375726882])\n","Epoch : [194] Train loss : [0.014882731916649001] Val Score : [0.9165787375726882])\n","Epoch : [195] Train loss : [0.015434464439749718] Val Score : [0.9165787375726882])\n","Epoch : [196] Train loss : [0.0154684345637049] Val Score : [0.9165787375726882])\n","Epoch : [197] Train loss : [0.017345172752227103] Val Score : [0.9165787375726882])\n","Epoch : [198] Train loss : [0.014181258156895638] Val Score : [0.9165787375726882])\n","Epoch 00199: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch : [199] Train loss : [0.014692552121622222] Val Score : [0.9165787375726882])\n","Epoch : [200] Train loss : [0.016489781040166105] Val Score : [0.9165787375726882])\n","Epoch : [201] Train loss : [0.016399750619062355] Val Score : [0.9165787375726882])\n","Epoch : [202] Train loss : [0.015865104406007698] Val Score : [0.9165787375726882])\n","Epoch : [203] Train loss : [0.015577911931489195] Val Score : [0.9165787375726882])\n","Epoch : [204] Train loss : [0.014113230098571097] Val Score : [0.9165787375726882])\n","Epoch : [205] Train loss : [0.014067914203873702] Val Score : [0.9165787375726882])\n","Epoch : [206] Train loss : [0.014941991306841373] Val Score : [0.9165787375726882])\n","Epoch : [207] Train loss : [0.014584751932748727] Val Score : [0.9165787375726882])\n","Epoch : [208] Train loss : [0.013907891032951218] Val Score : [0.9165787375726882])\n","Epoch : [209] Train loss : [0.01429551826523883] Val Score : [0.9165787375726882])\n","Epoch 00210: reducing learning rate of group 0 to 1.9073e-08.\n","Epoch : [210] Train loss : [0.013283209343041693] Val Score : [0.9165787375726882])\n","Epoch : [211] Train loss : [0.017523695980863913] Val Score : [0.9165787375726882])\n","Epoch : [212] Train loss : [0.014155507619891847] Val Score : [0.9165787375726882])\n","Epoch : [213] Train loss : [0.01590806884425027] Val Score : [0.9165787375726882])\n","Epoch : [214] Train loss : [0.015204880785729204] Val Score : [0.9165787375726882])\n","Epoch : [215] Train loss : [0.01518711487629584] Val Score : [0.9165787375726882])\n","Epoch : [216] Train loss : [0.015000134041266782] Val Score : [0.9165787375726882])\n","Epoch : [217] Train loss : [0.014225281774997711] Val Score : [0.9165787375726882])\n","Epoch : [218] Train loss : [0.015708831005862782] Val Score : [0.9165787375726882])\n","Epoch : [219] Train loss : [0.017360596917569637] Val Score : [0.9165787375726882])\n","Epoch : [220] Train loss : [0.018074726153697287] Val Score : [0.9165787375726882])\n","Epoch : [221] Train loss : [0.015579165890812874] Val Score : [0.9165787375726882])\n","Epoch : [222] Train loss : [0.01525827603680747] Val Score : [0.9165787375726882])\n","Epoch : [223] Train loss : [0.01512724334107978] Val Score : [0.9165787375726882])\n","Epoch : [224] Train loss : [0.015483313240110874] Val Score : [0.9165787375726882])\n","Epoch : [225] Train loss : [0.013961541599461011] Val Score : [0.9165787375726882])\n","Epoch : [226] Train loss : [0.0174770751701934] Val Score : [0.9165787375726882])\n","Epoch : [227] Train loss : [0.015105670451053552] Val Score : [0.9165787375726882])\n","Epoch : [228] Train loss : [0.015039266885391303] Val Score : [0.9165787375726882])\n","Epoch : [229] Train loss : [0.016436926488365446] Val Score : [0.9165787375726882])\n","Epoch : [230] Train loss : [0.015803740758981024] Val Score : [0.9165787375726882])\n","Epoch : [231] Train loss : [0.01656755126480545] Val Score : [0.9165787375726882])\n","Epoch : [232] Train loss : [0.01682224603635924] Val Score : [0.9165787375726882])\n","Epoch : [233] Train loss : [0.014674046076834202] Val Score : [0.9165787375726882])\n","Epoch : [234] Train loss : [0.015922830174011842] Val Score : [0.9165787375726882])\n","Epoch : [235] Train loss : [0.015132464202386993] Val Score : [0.9165787375726882])\n","Epoch : [236] Train loss : [0.016081883838134154] Val Score : [0.9165787375726882])\n","Epoch : [237] Train loss : [0.015475303466830934] Val Score : [0.9165787375726882])\n","Epoch : [238] Train loss : [0.01516457780131272] Val Score : [0.9165787375726882])\n","Epoch : [239] Train loss : [0.013683981927377837] Val Score : [0.9165787375726882])\n","Epoch : [240] Train loss : [0.01501501870474645] Val Score : [0.9165787375726882])\n","Epoch : [241] Train loss : [0.017156842829925672] Val Score : [0.9165787375726882])\n","Epoch : [242] Train loss : [0.014834803396037646] Val Score : [0.9165787375726882])\n","Epoch : [243] Train loss : [0.015665028909487382] Val Score : [0.9165787375726882])\n","Epoch : [244] Train loss : [0.014002104023737567] Val Score : [0.9165787375726882])\n","Epoch : [245] Train loss : [0.0154580186520304] Val Score : [0.9165787375726882])\n","Epoch : [246] Train loss : [0.01517147118491786] Val Score : [0.9165787375726882])\n","Epoch : [247] Train loss : [0.014217378970767771] Val Score : [0.9165787375726882])\n","Epoch : [248] Train loss : [0.016030486806162765] Val Score : [0.9165787375726882])\n","Epoch : [249] Train loss : [0.015274611966950553] Val Score : [0.9165787375726882])\n","Epoch : [250] Train loss : [0.015237309304731233] Val Score : [0.9165787375726882])\n","Epoch : [251] Train loss : [0.014613905256347997] Val Score : [0.9165787375726882])\n","Epoch : [252] Train loss : [0.015021270141005516] Val Score : [0.9165787375726882])\n","Epoch : [253] Train loss : [0.015010224655270576] Val Score : [0.9165787375726882])\n","Epoch : [254] Train loss : [0.015790696388908794] Val Score : [0.9165787375726882])\n","Epoch : [255] Train loss : [0.017157813667186668] Val Score : [0.9165787375726882])\n","Epoch : [256] Train loss : [0.012803706606583936] Val Score : [0.9165787375726882])\n","Epoch : [257] Train loss : [0.016526518256536553] Val Score : [0.9165787375726882])\n","Epoch : [258] Train loss : [0.01644589366125209] Val Score : [0.9165787375726882])\n","Epoch : [259] Train loss : [0.01641753369144031] Val Score : [0.9165787375726882])\n","Epoch : [260] Train loss : [0.014009661972522736] Val Score : [0.9165787375726882])\n","Epoch : [261] Train loss : [0.015092473077986921] Val Score : [0.9165787375726882])\n","Epoch : [262] Train loss : [0.01420306840113231] Val Score : [0.9165787375726882])\n","Epoch : [263] Train loss : [0.01447487170142787] Val Score : [0.9165787375726882])\n","Epoch : [264] Train loss : [0.013896195217967033] Val Score : [0.9165787375726882])\n","Epoch : [265] Train loss : [0.014374561607837677] Val Score : [0.9165787375726882])\n","Epoch : [266] Train loss : [0.015422648883291654] Val Score : [0.9165787375726882])\n","Epoch : [267] Train loss : [0.015064923092722893] Val Score : [0.9165787375726882])\n","Epoch : [268] Train loss : [0.016543567180633545] Val Score : [0.9165787375726882])\n","Epoch : [269] Train loss : [0.014529152507228511] Val Score : [0.9165787375726882])\n","Epoch : [270] Train loss : [0.01594259776175022] Val Score : [0.9165787375726882])\n","Epoch : [271] Train loss : [0.016231739361371313] Val Score : [0.9165787375726882])\n","Epoch : [272] Train loss : [0.014884912674980504] Val Score : [0.9165787375726882])\n","Epoch : [273] Train loss : [0.01364383434078523] Val Score : [0.9165787375726882])\n","Epoch : [274] Train loss : [0.01488705791000809] Val Score : [0.9165787375726882])\n","Epoch : [275] Train loss : [0.016728555783629417] Val Score : [0.9165787375726882])\n","Epoch : [276] Train loss : [0.014682765118777752] Val Score : [0.9165787375726882])\n","Epoch : [277] Train loss : [0.015660171130938188] Val Score : [0.9165787375726882])\n","Epoch : [278] Train loss : [0.014925198230360235] Val Score : [0.9165787375726882])\n","Epoch : [279] Train loss : [0.015531411261430808] Val Score : [0.9165787375726882])\n","Epoch : [280] Train loss : [0.016431272828153203] Val Score : [0.9165787375726882])\n","Epoch : [281] Train loss : [0.016171223617025783] Val Score : [0.9165787375726882])\n","Epoch : [282] Train loss : [0.017663101931767806] Val Score : [0.9165787375726882])\n","Epoch : [283] Train loss : [0.016940631637615815] Val Score : [0.9165787375726882])\n","Epoch : [284] Train loss : [0.015583983888583524] Val Score : [0.9165787375726882])\n","Epoch : [285] Train loss : [0.01504201056169612] Val Score : [0.9165787375726882])\n","Epoch : [286] Train loss : [0.014980149189276355] Val Score : [0.9165787375726882])\n","Epoch : [287] Train loss : [0.01529467198997736] Val Score : [0.9165787375726882])\n","Epoch : [288] Train loss : [0.01542836254728692] Val Score : [0.9165787375726882])\n","Epoch : [289] Train loss : [0.014602616562375001] Val Score : [0.9165787375726882])\n","Epoch : [290] Train loss : [0.01592676341533661] Val Score : [0.9165787375726882])\n","Epoch : [291] Train loss : [0.015291736594268255] Val Score : [0.9165787375726882])\n","Epoch : [292] Train loss : [0.016576750070921013] Val Score : [0.9165787375726882])\n","Epoch : [293] Train loss : [0.015232792922428675] Val Score : [0.9165787375726882])\n","Epoch : [294] Train loss : [0.014939228205808572] Val Score : [0.9165787375726882])\n","Epoch : [295] Train loss : [0.013954645954072475] Val Score : [0.9165787375726882])\n","Epoch : [296] Train loss : [0.015055915340781212] Val Score : [0.9165787375726882])\n","Epoch : [297] Train loss : [0.014912110886403493] Val Score : [0.9165787375726882])\n","Epoch : [298] Train loss : [0.014894706197082996] Val Score : [0.9165787375726882])\n","Epoch : [299] Train loss : [0.013974554437611784] Val Score : [0.9165787375726882])\n","Epoch : [300] Train loss : [0.014132791331836156] Val Score : [0.9165787375726882])\n","Epoch : [301] Train loss : [0.013919386214443616] Val Score : [0.9165787375726882])\n","Epoch : [302] Train loss : [0.014098489124860083] Val Score : [0.9165787375726882])\n","Epoch : [303] Train loss : [0.015525396248059613] Val Score : [0.9165787375726882])\n","Epoch : [304] Train loss : [0.015670486326728548] Val Score : [0.9165787375726882])\n","Epoch : [305] Train loss : [0.016534628878746713] Val Score : [0.9165787375726882])\n","Epoch : [306] Train loss : [0.01629733307553189] Val Score : [0.9165787375726882])\n","Epoch : [307] Train loss : [0.015615061856806278] Val Score : [0.9165787375726882])\n","Epoch : [308] Train loss : [0.014700392128101416] Val Score : [0.9165787375726882])\n","Epoch : [309] Train loss : [0.017019657285085747] Val Score : [0.9165787375726882])\n","Epoch : [310] Train loss : [0.01588714388864381] Val Score : [0.9165787375726882])\n","Epoch : [311] Train loss : [0.015799873375466893] Val Score : [0.9165787375726882])\n","Epoch : [312] Train loss : [0.01741512372557606] Val Score : [0.9165787375726882])\n","Epoch : [313] Train loss : [0.015885795333555768] Val Score : [0.9165787375726882])\n","Epoch : [314] Train loss : [0.01575192835714136] Val Score : [0.9165787375726882])\n","Epoch : [315] Train loss : [0.01517782945718084] Val Score : [0.9165787375726882])\n","Epoch : [316] Train loss : [0.015817349909671714] Val Score : [0.9165787375726882])\n","Epoch : [317] Train loss : [0.015681414998003414] Val Score : [0.9165787375726882])\n","Epoch : [318] Train loss : [0.014975695604724544] Val Score : [0.9165787375726882])\n","Epoch : [319] Train loss : [0.015000973295952593] Val Score : [0.9165787375726882])\n","Epoch : [320] Train loss : [0.013485988468996115] Val Score : [0.9165787375726882])\n","Epoch : [321] Train loss : [0.01662116710628782] Val Score : [0.9165787375726882])\n","Epoch : [322] Train loss : [0.015409949235618114] Val Score : [0.9165787375726882])\n","Epoch : [323] Train loss : [0.01427396440080234] Val Score : [0.9165787375726882])\n","Epoch : [324] Train loss : [0.01670921247984682] Val Score : [0.9165787375726882])\n","Epoch : [325] Train loss : [0.01494604628533125] Val Score : [0.9165787375726882])\n","Epoch : [326] Train loss : [0.01676597645772355] Val Score : [0.9165787375726882])\n","Epoch : [327] Train loss : [0.014444294784750258] Val Score : [0.9165787375726882])\n","Epoch : [328] Train loss : [0.01579044958842652] Val Score : [0.9165787375726882])\n","Epoch : [329] Train loss : [0.014938082545995712] Val Score : [0.9165787375726882])\n","Epoch : [330] Train loss : [0.015353004980300154] Val Score : [0.9165787375726882])\n","Epoch : [331] Train loss : [0.01450481531875474] Val Score : [0.9165787375726882])\n","Epoch : [332] Train loss : [0.014560915928866183] Val Score : [0.9165787375726882])\n","Epoch : [333] Train loss : [0.014745056895273072] Val Score : [0.9165787375726882])\n","Epoch : [334] Train loss : [0.01348980316626174] Val Score : [0.9165787375726882])\n","Epoch : [335] Train loss : [0.014696864544280938] Val Score : [0.9165787375726882])\n","Epoch : [336] Train loss : [0.015592087326305253] Val Score : [0.9165787375726882])\n","Epoch : [337] Train loss : [0.01492695470473596] Val Score : [0.9165787375726882])\n","Epoch : [338] Train loss : [0.016869406748030866] Val Score : [0.9165787375726882])\n","Epoch : [339] Train loss : [0.01859366680894579] Val Score : [0.9165787375726882])\n","Epoch : [340] Train loss : [0.01547159587166139] Val Score : [0.9165787375726882])\n","Epoch : [341] Train loss : [0.016062705112355097] Val Score : [0.9165787375726882])\n","Epoch : [342] Train loss : [0.015410043698336397] Val Score : [0.9165787375726882])\n","Epoch : [343] Train loss : [0.014809571339615754] Val Score : [0.9165787375726882])\n","Epoch : [344] Train loss : [0.01367942536515849] Val Score : [0.9165787375726882])\n","Epoch : [345] Train loss : [0.013794735606227602] Val Score : [0.9165787375726882])\n","Epoch : [346] Train loss : [0.01457862343106951] Val Score : [0.9165787375726882])\n","Epoch : [347] Train loss : [0.017356287022786483] Val Score : [0.9165787375726882])\n","Epoch : [348] Train loss : [0.017439423661146845] Val Score : [0.9165787375726882])\n","Epoch : [349] Train loss : [0.016105124726891518] Val Score : [0.9165787375726882])\n","Epoch : [350] Train loss : [0.01681773497589997] Val Score : [0.9165787375726882])\n","Epoch : [351] Train loss : [0.014583708718419075] Val Score : [0.9165787375726882])\n","Epoch : [352] Train loss : [0.014587684534490108] Val Score : [0.9165787375726882])\n","Epoch : [353] Train loss : [0.013747507839330606] Val Score : [0.9165787375726882])\n","Epoch : [354] Train loss : [0.012964615864413125] Val Score : [0.9165787375726882])\n","Epoch : [355] Train loss : [0.01571528533739703] Val Score : [0.9165787375726882])\n","Epoch : [356] Train loss : [0.01532492640295199] Val Score : [0.9165787375726882])\n","Epoch : [357] Train loss : [0.015241417501653944] Val Score : [0.9165787375726882])\n","Epoch : [358] Train loss : [0.015131405953850065] Val Score : [0.9165787375726882])\n","Epoch : [359] Train loss : [0.016025112010538578] Val Score : [0.9165787375726882])\n","Epoch : [360] Train loss : [0.014827330064560686] Val Score : [0.9165787375726882])\n","Epoch : [361] Train loss : [0.015857941071902002] Val Score : [0.9165787375726882])\n","Epoch : [362] Train loss : [0.014988655357488565] Val Score : [0.9165787375726882])\n","Epoch : [363] Train loss : [0.015793988880302225] Val Score : [0.9165787375726882])\n","Epoch : [364] Train loss : [0.015039042170558656] Val Score : [0.9165787375726882])\n","Epoch : [365] Train loss : [0.01415270141192845] Val Score : [0.9165787375726882])\n","Epoch : [366] Train loss : [0.015598956495523453] Val Score : [0.9165787375726882])\n","Epoch : [367] Train loss : [0.014184424919741494] Val Score : [0.9165787375726882])\n","Epoch : [368] Train loss : [0.015833736663418158] Val Score : [0.9165787375726882])\n","Epoch : [369] Train loss : [0.014659085843179907] Val Score : [0.9165787375726882])\n","Epoch : [370] Train loss : [0.01421322806605271] Val Score : [0.9165787375726882])\n","Epoch : [371] Train loss : [0.015597677789628506] Val Score : [0.9165787375726882])\n","Epoch : [372] Train loss : [0.013845260121992655] Val Score : [0.9165787375726882])\n","Epoch : [373] Train loss : [0.017965179601950303] Val Score : [0.9165787375726882])\n","Epoch : [374] Train loss : [0.015190612258655685] Val Score : [0.9165787375726882])\n","Epoch : [375] Train loss : [0.014757767452725343] Val Score : [0.9165787375726882])\n","Epoch : [376] Train loss : [0.016203905854906355] Val Score : [0.9165787375726882])\n","Epoch : [377] Train loss : [0.014334522453801972] Val Score : [0.9165787375726882])\n","Epoch : [378] Train loss : [0.015133850143424101] Val Score : [0.9165787375726882])\n","Epoch : [379] Train loss : [0.014663290099373885] Val Score : [0.9165787375726882])\n","Epoch : [380] Train loss : [0.015421692681099688] Val Score : [0.9165787375726882])\n","Epoch : [381] Train loss : [0.016724031551608017] Val Score : [0.9165787375726882])\n","Epoch : [382] Train loss : [0.01807986944913864] Val Score : [0.9165787375726882])\n","Epoch : [383] Train loss : [0.015512889118066855] Val Score : [0.9165787375726882])\n","Epoch : [384] Train loss : [0.01439203800899642] Val Score : [0.9165787375726882])\n","Epoch : [385] Train loss : [0.014148018722023283] Val Score : [0.9165787375726882])\n","Epoch : [386] Train loss : [0.013955713382789068] Val Score : [0.9165787375726882])\n","Epoch : [387] Train loss : [0.013077597532953535] Val Score : [0.9165787375726882])\n","Epoch : [388] Train loss : [0.01652033001716648] Val Score : [0.9165787375726882])\n","Epoch : [389] Train loss : [0.0164771101304463] Val Score : [0.9165787375726882])\n","Epoch : [390] Train loss : [0.013815367195223058] Val Score : [0.9165787375726882])\n","Epoch : [391] Train loss : [0.01523538732102939] Val Score : [0.9165787375726882])\n","Epoch : [392] Train loss : [0.016435922921768258] Val Score : [0.9165787375726882])\n","Epoch : [393] Train loss : [0.014929937863988536] Val Score : [0.9165787375726882])\n","Epoch : [394] Train loss : [0.016542984305747917] Val Score : [0.9165787375726882])\n","Epoch : [395] Train loss : [0.015321074984967709] Val Score : [0.9165787375726882])\n","Epoch : [396] Train loss : [0.015929522258894786] Val Score : [0.9165787375726882])\n","Epoch : [397] Train loss : [0.014896881633571215] Val Score : [0.9165787375726882])\n","Epoch : [398] Train loss : [0.016939095088413784] Val Score : [0.9165787375726882])\n","Epoch : [399] Train loss : [0.015053252157356058] Val Score : [0.9165787375726882])\n"]}]},{"cell_type":"markdown","metadata":{"id":"LikG8E2yw_2C"},"source":["### 추론"]},{"cell_type":"code","source":["# 학습된 내용 불러오기\n","model = AutoEncoder()\n","model.load_state_dict(torch.load('./best_model2.pth'))\n","model = nn.DataParallel(model)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DasDEq98XI4f","executionInfo":{"status":"ok","timestamp":1658823966419,"user_tz":-540,"elapsed":261,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"21e30bc3-b4ea-49ee-89f1-9ee2918b8c6c"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataParallel(\n","  (module): AutoEncoder(\n","    (Encoder): Sequential(\n","      (0): Linear(in_features=30, out_features=64, bias=True)\n","      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): PReLU(num_parameters=1)\n","      (3): Linear(in_features=64, out_features=128, bias=True)\n","      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): PReLU(num_parameters=1)\n","    )\n","    (Decoder): Sequential(\n","      (0): Linear(in_features=128, out_features=64, bias=True)\n","      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): PReLU(num_parameters=1)\n","      (3): Linear(in_features=64, out_features=30, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["test_dataset = MyDataset(test_df, False)\n","test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=2)"],"metadata":{"id":"OyoKdvTVXFtv","executionInfo":{"status":"ok","timestamp":1658823971272,"user_tz":-540,"elapsed":474,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","execution_count":30,"metadata":{"id":"tfsaY4q8w_2F","executionInfo":{"status":"ok","timestamp":1658823979266,"user_tz":-540,"elapsed":1214,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["preds = prediction(model, 0.95, test_loader, device)"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"Dam9mtoow_2G","executionInfo":{"status":"ok","timestamp":1658824011237,"user_tz":-540,"elapsed":888,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["submit = pd.read_csv('./drive/MyDrive/data/sample_submission.csv')\n","submit['Class'] = preds\n","submit.to_csv('./drive/MyDrive/autoencoder_test_hwan2.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.6 ('study')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"c530038a4968235b14954dfb7e9ce27eac1d97b010045a73365830ad480ab54b"}},"colab":{"name":"AutoEncoder_study.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}