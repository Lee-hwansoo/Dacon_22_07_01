{"cells":[{"cell_type":"markdown","metadata":{"id":"2jD9PzSjw_x7"},"source":["# AutoEncoder Study"]},{"cell_type":"markdown","metadata":{"id":"Qvdx2a32w_ye"},"source":["## Colab setting"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oFZV1LoMw_yh","executionInfo":{"status":"ok","timestamp":1658829468155,"user_tz":-540,"elapsed":23293,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"6baa73d9-7d52-4b5f-c62d-23016389288d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Colab\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-EZM11QFw_ys","executionInfo":{"status":"ok","timestamp":1658829474723,"user_tz":-540,"elapsed":4252,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["# Colab\n","import pandas as pd\n","train_df = pd.read_csv('./drive/MyDrive/data/train.csv')\n","train_df = train_df.drop(columns=['ID'])\n","val_df = pd.read_csv('./drive/MyDrive/data/val.csv')\n","val_df = val_df.drop(columns=['ID'])\n","test_df = pd.read_csv('./drive/MyDrive/data/test.csv')\n","test_df = test_df.drop(columns=['ID'])"]},{"cell_type":"markdown","metadata":{"id":"LJDqlr8Aw_yu"},"source":["## Import"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8CL_XI2Hw_yw","executionInfo":{"status":"ok","timestamp":1658829477460,"user_tz":-540,"elapsed":2739,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import random\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.auto import tqdm\n","from sklearn.covariance import EllipticEnvelope\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","import warnings\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"markdown","metadata":{"id":"yhrckT-8w_y3"},"source":["## Data Load"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"FO7pxbmcw_y4","executionInfo":{"status":"ok","timestamp":1658829477461,"user_tz":-540,"elapsed":9,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["# Local\n","# train_df = pd.read_csv('./data/train.csv')\n","# train_df = train_df.drop(columns=['ID'])\n","# val_df = pd.read_csv('./data/val.csv')\n","# val_df = val_df.drop(columns=['ID'])\n","# test_df = pd.read_csv('./data/test.csv')\n","# test_df = test_df.drop(columns=['ID'])"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tqfn-Wibw_zO","executionInfo":{"status":"ok","timestamp":1658829477462,"user_tz":-540,"elapsed":10,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"9f90c072-4b50-49b0-f618-6cc0f8de91c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Normals 99.89 % of the dataset\n","Frauds 0.11 % of the dataset\n","Validation contamination : [0.0010551491277433877]\n"]}],"source":["# validation data의 정상, 불량 거래 데이터 비율 확인\n","print('Normals', round(val_df['Class'].value_counts()[0]/len(val_df) * 100,2), '% of the dataset')\n","print('Frauds', round(val_df['Class'].value_counts()[1]/len(val_df) * 100,2), '% of the dataset')\n","\n","val_normal, val_fraud = val_df['Class'].value_counts()\n","val_contamination = val_fraud / val_normal\n","print(f'Validation contamination : [{val_contamination}]')"]},{"cell_type":"markdown","source":["## EllipticEnvelope"],"metadata":{"id":"FhvfFT_1uSUB"}},{"cell_type":"code","source":["# 가설 설정 : Train dataset도 Validation dataset과 동일한 비율로 사기거래가 발생 했을 것이다. -> model parameter : contamination=val_contamination(=0.001055) 적용\n","model3 = EllipticEnvelope(support_fraction = 0.994, contamination = val_contamination, random_state = 42)\n","model3.fit(train_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dg3Zeof8uanv","executionInfo":{"status":"ok","timestamp":1658829514037,"user_tz":-540,"elapsed":36581,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"f7ad0bd5-e914-4ed7-dab3-44287110dce7"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EllipticEnvelope(contamination=0.0010551491277433877, random_state=42,\n","                 support_fraction=0.994)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["def get_pred_label(model, x, k):\n","  prob = model.score_samples(x)\n","  prob = torch.tensor(prob, dtype = torch.float)\n","  topk_indices = torch.topk(prob, k = k, largest = False).indices\n","\n","  pred = torch.zeros(len(x), dtype = torch.long)\n","  pred[topk_indices] = 1\n","  return pred.tolist(), prob.tolist()"],"metadata":{"id":"utYvB7eouaj3","executionInfo":{"status":"ok","timestamp":1658829514038,"user_tz":-540,"elapsed":4,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["val_x = val_df.drop(columns=['Class']) # Input Data\n","val_y = val_df['Class'] # Label\n","\n","val_pred, val_prob = get_pred_label(model3, val_x, 29)\n","val_score = f1_score(val_y, val_pred, average='macro')\n","print(f'Validation F1 Score : [{val_score}]')\n","print(classification_report(val_y, val_pred))\n","tn, fp, fn, tp = confusion_matrix(val_y, val_pred).ravel()\n","print('tp : ', tp, ', fp : ', fp, ', tn : ', tn, ', fn : ', fn)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SatAazcXuaf1","executionInfo":{"status":"ok","timestamp":1658829538188,"user_tz":-540,"elapsed":438,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"f8a8aae5-15e9-4aaa-b17c-c033fde725ed"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation F1 Score : [0.9236496787663914]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     28432\n","           1       0.86      0.83      0.85        30\n","\n","    accuracy                           1.00     28462\n","   macro avg       0.93      0.92      0.92     28462\n","weighted avg       1.00      1.00      1.00     28462\n","\n","tp :  25 , fp :  4 , tn :  28428 , fn :  5\n"]}]},{"cell_type":"code","source":["train_pred = model3.predict(train_df)"],"metadata":{"id":"VISldpyc5l0H","executionInfo":{"status":"ok","timestamp":1658829540002,"user_tz":-540,"elapsed":6,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def get_pred_label2(model_pred):\n","    # IsolationForest 모델 출력 (1:정상, -1:불량(사기)) 이므로 (0:정상, 1:불량(사기))로 Label 변환\n","    model_pred = np.where(model_pred == 1, 0, model_pred)\n","    model_pred = np.where(model_pred == -1, 1, model_pred)\n","    return model_pred"],"metadata":{"id":"CSZxtFZ67Yd1","executionInfo":{"status":"ok","timestamp":1658829540005,"user_tz":-540,"elapsed":8,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train_pred = get_pred_label2(train_pred)\n","train_df['Class'] = train_pred\n","train_df = train_df[train_df['Class']==0]\n","train_df=train_df.drop(columns=['Class'])"],"metadata":{"id":"KRb1Sh_Juacs","executionInfo":{"status":"ok","timestamp":1658829543439,"user_tz":-540,"elapsed":314,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iqhlEWiXw_1U"},"source":["## Pytorch"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zPIdtOt0w_1W","executionInfo":{"status":"ok","timestamp":1658829547150,"user_tz":-540,"elapsed":499,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"aece938f-5241-4509-b4a3-e62fa155d8da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using Device: cuda\n"]}],"source":["# device 설정, gpu 있을시 gpu사용\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(\"Using Device:\", device)"]},{"cell_type":"markdown","metadata":{"id":"rLH4Zic8w_1w"},"source":["### Hyper parameter"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"jydhpC5vw_1x","executionInfo":{"status":"ok","timestamp":1658829547851,"user_tz":-540,"elapsed":7,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["EPOCHS = 400\n","LR = 1e-2\n","BS = 16384\n","SEED = 123"]},{"cell_type":"markdown","metadata":{"id":"Uoffh2wuw_1z"},"source":["### Fix Seed"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"lsogABxmw_10","executionInfo":{"status":"ok","timestamp":1658829549088,"user_tz":-540,"elapsed":12,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(SEED) # Seed 고정"]},{"cell_type":"markdown","metadata":{"id":"yjc7_z-ww_12"},"source":[" ### Make DataSet    "]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ccZYmk45w_13","executionInfo":{"status":"ok","timestamp":1658829550354,"user_tz":-540,"elapsed":6,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["# eval_ mode를 통해 validation, 즉 평가를 위한 데이터 val.df와 train.df 분리\n","# val_df의 Class인 정상 거래, 비정상 거래 내용을 labels로, 나머지 feature 값을 df로 저장\n","# train_df의 값을 df로 저장\n","class MyDataset(Dataset):\n","    def __init__(self, df, eval_mode):\n","        self.df = df\n","        self.eval_mode = eval_mode\n","        if self.eval_mode:\n","            self.labels = self.df['Class'].values\n","            self.df = self.df.drop(columns=['Class']).values\n","        else:\n","            self.df = self.df.values\n","        \n","    def __getitem__(self, index):\n","        if self.eval_mode:\n","            self.x = self.df[index]\n","            self.y = self.labels[index]\n","            return torch.Tensor(self.x), self.y\n","        else:\n","            self.x = self.df[index]\n","            return torch.Tensor(self.x)\n","        \n","    def __len__(self):\n","        return len(self.df)"]},{"cell_type":"markdown","metadata":{"id":"xxx2FiSIw_15"},"source":["### Pytorch Data Load"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Lj20SOHPw_16","executionInfo":{"status":"ok","timestamp":1658829551844,"user_tz":-540,"elapsed":6,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["# shuffle을 통해 데이터 과적합해결(신경망이 데이터의 순서를 예측하지 못하게 한다)\n","train_dataset = MyDataset(df=train_df, eval_mode=False)\n","train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=2)\n","\n","\n","val_dataset = MyDataset(df = val_df, eval_mode=True)\n","val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=2)"]},{"cell_type":"markdown","metadata":{"id":"dxEGa7Sbw_18"},"source":["### AutoEncoder 구조(신경망)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"xvRnl4Flw_19","executionInfo":{"status":"ok","timestamp":1658829553623,"user_tz":-540,"elapsed":6,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["# neural network를 이용해서 AutoEncoder Layer 설정\n","# BatchNorm1d 정규화 레이어 사용\n","# LeakyReLU 활성화 함수 사용\n","class AutoEncoder(nn.Module):\n","    def __init__(self):\n","        super(AutoEncoder, self).__init__()\n","        self.Encoder = nn.Sequential(\n","            nn.Linear(30,64),\n","            nn.BatchNorm1d(64),\n","            nn.PReLU(),\n","            nn.Linear(64,128),\n","            nn.BatchNorm1d(128),\n","            nn.PReLU(),\n","        )\n","        self.Decoder = nn.Sequential(\n","            nn.Linear(128,64),\n","            nn.BatchNorm1d(64),\n","            nn.PReLU(),\n","            nn.Linear(64,30),\n","        )\n","        \n","    def forward(self, x):\n","        x = self.Encoder(x)\n","        x = self.Decoder(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"qkcAIrKhw_1-"},"source":["### Train"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"uXvK-WEGw_1_","executionInfo":{"status":"ok","timestamp":1658829555733,"user_tz":-540,"elapsed":471,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["class Trainer():\n","    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.scheduler = scheduler\n","        self.device = device\n","        # Loss Function\n","        self.criterion = nn.L1Loss().to(self.device)\n","        \n","    def fit(self, ):\n","        self.model.to(self.device)\n","        best_score = 0\n","        for epoch in range(EPOCHS):\n","            self.model.train()\n","            train_loss = []\n","            for x in iter(self.train_loader):\n","                x = x.float().to(self.device)\n","                # 역전파 단계 전에, optimizer 객체를 사용하여 (모델의 학습 가능한 가중치인) 갱신할\n","                # 변수들에 대한 모든 변화도(gradient)를 0으로 만듭니다. 이렇게 하는 이유는 기본적으로 \n","                # .backward()를 호출할 때마다 변화도가 버퍼(buffer)에 (덮어쓰지 않고) 누적되기\n","                # 때문입니다. 더 자세한 내용은 torch.autograd.backward에 대한 문서를 참조하세요.\n","                self.optimizer.zero_grad()\n","\n","                # AutoEncoder 통과한 예측값\n","                _x = self.model(x)\n","                loss = self.criterion(x, _x)\n","\n","                # 역전파 단계: 모델의 매개변수들에 대한 손실의 변화도를 계산합니다.\n","                loss.backward()\n","                # optimizer의 step 함수를 호출하면 매개변수가 갱신됩니다.\n","                self.optimizer.step()\n","\n","                train_loss.append(loss.item())\n","\n","            score = self.validation(self.model, 0.95)\n","            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n","\n","            if self.scheduler is not None:\n","                self.scheduler.step(score)\n","\n","            if best_score < score:\n","                best_score = score\n","                torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n","    \n","    def validation(self, eval_model, thr):\n","        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","        #  model.eval()는 이런 layer들의 동작을 inference(eval) mode로 바꿔준다는 목적\n","        eval_model.eval()\n","        pred = []\n","        true = []\n","        # torch.no_grad()의 주된 목적은 autograd(자동으로 gradient를 트래킹)를 끔으로써 메모리 사용량을 줄이고 연산 속도를 높히기 위함\n","        with torch.no_grad():\n","            for x, y in iter(self.val_loader):\n","                x = x.float().to(self.device)\n","\n","                _x = self.model(x)\n","                diff = cos(x, _x).cpu().tolist()\n","                #유사도 0.95보다 작은것은 이상거래 1, 아닌 것은 정상거래 0\n","                batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n","                pred += batch_pred\n","                true += y.tolist()\n","\n","        return f1_score(true, pred, average='macro')"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HCz4L786w_2B","executionInfo":{"status":"ok","timestamp":1658830115334,"user_tz":-540,"elapsed":557840,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"a4e38df9-f250-4ff9-9581-542afc24db47"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : [0] Train loss : [0.5191410779953003] Val Score : [0.01212568109357687])\n","Epoch : [1] Train loss : [0.2957411216838019] Val Score : [0.3060956055145746])\n","Epoch : [2] Train loss : [0.1946136291537966] Val Score : [0.47707733249758916])\n","Epoch : [3] Train loss : [0.14337074969496047] Val Score : [0.5010501588718952])\n","Epoch : [4] Train loss : [0.11181453934737615] Val Score : [0.5097059233701152])\n","Epoch : [5] Train loss : [0.09384418491806303] Val Score : [0.517659362423344])\n","Epoch : [6] Train loss : [0.08071373615946088] Val Score : [0.5282520900484803])\n","Epoch : [7] Train loss : [0.07242293123688016] Val Score : [0.535260773313533])\n","Epoch : [8] Train loss : [0.06867049634456635] Val Score : [0.543110595636484])\n","Epoch : [9] Train loss : [0.06348455963390214] Val Score : [0.5549207791353115])\n","Epoch : [10] Train loss : [0.058882229562316625] Val Score : [0.57352295988857])\n","Epoch : [11] Train loss : [0.055163873093468804] Val Score : [0.5859624910479828])\n","Epoch : [12] Train loss : [0.049077394285372326] Val Score : [0.6016121257612063])\n","Epoch : [13] Train loss : [0.05388410921607699] Val Score : [0.6148242742323416])\n","Epoch : [14] Train loss : [0.05509485889758382] Val Score : [0.6715772162000156])\n","Epoch : [15] Train loss : [0.049182719950165064] Val Score : [0.7422520697342344])\n","Epoch : [16] Train loss : [0.04832327578748975] Val Score : [0.7600119366040216])\n","Epoch : [17] Train loss : [0.048540347920996804] Val Score : [0.7655703273293624])\n","Epoch : [18] Train loss : [0.05022069386073521] Val Score : [0.7655703273293624])\n","Epoch : [19] Train loss : [0.04618678508060319] Val Score : [0.7713696202996474])\n","Epoch : [20] Train loss : [0.04430527665785381] Val Score : [0.777425875747303])\n","Epoch : [21] Train loss : [0.04257187673023769] Val Score : [0.777425875747303])\n","Epoch : [22] Train loss : [0.0413747312767165] Val Score : [0.7837566139258728])\n","Epoch : [23] Train loss : [0.04197012473429952] Val Score : [0.7837566139258728])\n","Epoch : [24] Train loss : [0.040301162749528885] Val Score : [0.7903809848799157])\n","Epoch : [25] Train loss : [0.03948455995747021] Val Score : [0.8122361199071142])\n","Epoch : [26] Train loss : [0.040193383182798116] Val Score : [0.8376267560436427])\n","Epoch : [27] Train loss : [0.03992098197340965] Val Score : [0.8422634702634115])\n","Epoch : [28] Train loss : [0.04034367044057165] Val Score : [0.872984830495149])\n","Epoch : [29] Train loss : [0.03629971242376736] Val Score : [0.8967110829723166])\n","Epoch : [30] Train loss : [0.03800392523407936] Val Score : [0.9165787375726882])\n","Epoch : [31] Train loss : [0.037798481328146796] Val Score : [0.9165787375726882])\n","Epoch : [32] Train loss : [0.03597575319664819] Val Score : [0.9165787375726882])\n","Epoch : [33] Train loss : [0.03363571848188128] Val Score : [0.9165787375726882])\n","Epoch : [34] Train loss : [0.03489725823913302] Val Score : [0.9165787375726882])\n","Epoch : [35] Train loss : [0.034406607172318866] Val Score : [0.9165787375726882])\n","Epoch : [36] Train loss : [0.032976780885032246] Val Score : [0.9165787375726882])\n","Epoch : [37] Train loss : [0.031743984669446945] Val Score : [0.9165787375726882])\n","Epoch : [38] Train loss : [0.03352381741361959] Val Score : [0.9165787375726882])\n","Epoch : [39] Train loss : [0.033614612849695344] Val Score : [0.9165787375726882])\n","Epoch : [40] Train loss : [0.03395352140069008] Val Score : [0.9165787375726882])\n","Epoch : [41] Train loss : [0.03197527011590345] Val Score : [0.9165787375726882])\n","Epoch 00042: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch : [42] Train loss : [0.02819226762013776] Val Score : [0.9165787375726882])\n","Epoch : [43] Train loss : [0.02677689545920917] Val Score : [0.9165787375726882])\n","Epoch : [44] Train loss : [0.02483343838581017] Val Score : [0.9165787375726882])\n","Epoch : [45] Train loss : [0.027821902983954976] Val Score : [0.9165787375726882])\n","Epoch : [46] Train loss : [0.02598255979163306] Val Score : [0.9165787375726882])\n","Epoch : [47] Train loss : [0.02742346535835947] Val Score : [0.9165787375726882])\n","Epoch : [48] Train loss : [0.026018877646752765] Val Score : [0.9165787375726882])\n","Epoch : [49] Train loss : [0.02486563819859709] Val Score : [0.9165787375726882])\n","Epoch : [50] Train loss : [0.024544787726231983] Val Score : [0.9165787375726882])\n","Epoch : [51] Train loss : [0.025852442319904054] Val Score : [0.9165787375726882])\n","Epoch : [52] Train loss : [0.024727987125515938] Val Score : [0.9165787375726882])\n","Epoch 00053: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch : [53] Train loss : [0.02429991854088647] Val Score : [0.9165787375726882])\n","Epoch : [54] Train loss : [0.02122355332331998] Val Score : [0.9165787375726882])\n","Epoch : [55] Train loss : [0.020223347204072133] Val Score : [0.9165787375726882])\n","Epoch : [56] Train loss : [0.022311286202498844] Val Score : [0.9165787375726882])\n","Epoch : [57] Train loss : [0.019556180707045963] Val Score : [0.9165787375726882])\n","Epoch : [58] Train loss : [0.021934293742690767] Val Score : [0.9165787375726882])\n","Epoch : [59] Train loss : [0.020154340458767756] Val Score : [0.9165787375726882])\n","Epoch : [60] Train loss : [0.019062609544822147] Val Score : [0.9165787375726882])\n","Epoch : [61] Train loss : [0.020537541647042547] Val Score : [0.9165787375726882])\n","Epoch : [62] Train loss : [0.020624222233891487] Val Score : [0.9165787375726882])\n","Epoch : [63] Train loss : [0.021455309220722744] Val Score : [0.9165787375726882])\n","Epoch 00064: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch : [64] Train loss : [0.019276445465428487] Val Score : [0.9165787375726882])\n","Epoch : [65] Train loss : [0.016857111028262546] Val Score : [0.9165787375726882])\n","Epoch : [66] Train loss : [0.01728994944798095] Val Score : [0.9165787375726882])\n","Epoch : [67] Train loss : [0.017020083697778837] Val Score : [0.9165787375726882])\n","Epoch : [68] Train loss : [0.01780150192124503] Val Score : [0.9165787375726882])\n","Epoch : [69] Train loss : [0.017134075053036213] Val Score : [0.9165787375726882])\n","Epoch : [70] Train loss : [0.018159676476248672] Val Score : [0.9165787375726882])\n","Epoch : [71] Train loss : [0.01622139396412032] Val Score : [0.9165787375726882])\n","Epoch : [72] Train loss : [0.017747334470706328] Val Score : [0.9165787375726882])\n","Epoch : [73] Train loss : [0.018760812202734605] Val Score : [0.9165787375726882])\n","Epoch : [74] Train loss : [0.01770397994135107] Val Score : [0.9165787375726882])\n","Epoch 00075: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch : [75] Train loss : [0.01622813194990158] Val Score : [0.9165787375726882])\n","Epoch : [76] Train loss : [0.015091590184186186] Val Score : [0.9165787375726882])\n","Epoch : [77] Train loss : [0.015207462411906039] Val Score : [0.9165787375726882])\n","Epoch : [78] Train loss : [0.01457997424794095] Val Score : [0.9165787375726882])\n","Epoch : [79] Train loss : [0.014694552735558577] Val Score : [0.9165787375726882])\n","Epoch : [80] Train loss : [0.015391097936247076] Val Score : [0.9165787375726882])\n","Epoch : [81] Train loss : [0.013829628537808145] Val Score : [0.9165787375726882])\n","Epoch : [82] Train loss : [0.014018825787518705] Val Score : [0.9165787375726882])\n","Epoch : [83] Train loss : [0.01606012401836259] Val Score : [0.9165787375726882])\n","Epoch : [84] Train loss : [0.014311687222548894] Val Score : [0.9165787375726882])\n","Epoch : [85] Train loss : [0.016759285171117102] Val Score : [0.9165787375726882])\n","Epoch 00086: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch : [86] Train loss : [0.014054385679108756] Val Score : [0.9165787375726882])\n","Epoch : [87] Train loss : [0.013340858343456472] Val Score : [0.9165787375726882])\n","Epoch : [88] Train loss : [0.013456148893705435] Val Score : [0.9165787375726882])\n","Epoch : [89] Train loss : [0.012573339444186007] Val Score : [0.9165787375726882])\n","Epoch : [90] Train loss : [0.014108166763825076] Val Score : [0.9165787375726882])\n","Epoch : [91] Train loss : [0.017397363537124226] Val Score : [0.9165787375726882])\n","Epoch : [92] Train loss : [0.013475147208997182] Val Score : [0.9165787375726882])\n","Epoch : [93] Train loss : [0.013586524873971939] Val Score : [0.9165787375726882])\n","Epoch : [94] Train loss : [0.014205944990473134] Val Score : [0.9165787375726882])\n","Epoch : [95] Train loss : [0.01439337246119976] Val Score : [0.9165787375726882])\n","Epoch : [96] Train loss : [0.01396045833826065] Val Score : [0.9165787375726882])\n","Epoch 00097: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch : [97] Train loss : [0.014136960463864463] Val Score : [0.9165787375726882])\n","Epoch : [98] Train loss : [0.01409968121775559] Val Score : [0.9165787375726882])\n","Epoch : [99] Train loss : [0.014809615111776761] Val Score : [0.9165787375726882])\n","Epoch : [100] Train loss : [0.013029998700533594] Val Score : [0.9165787375726882])\n","Epoch : [101] Train loss : [0.013579110348863261] Val Score : [0.9165787375726882])\n","Epoch : [102] Train loss : [0.01348398971770491] Val Score : [0.9165787375726882])\n","Epoch : [103] Train loss : [0.01371929222451789] Val Score : [0.9165787375726882])\n","Epoch : [104] Train loss : [0.012604279177529472] Val Score : [0.9165787375726882])\n","Epoch : [105] Train loss : [0.011476409222398485] Val Score : [0.9165787375726882])\n","Epoch : [106] Train loss : [0.01391752835895334] Val Score : [0.9165787375726882])\n","Epoch : [107] Train loss : [0.014512104780546256] Val Score : [0.9165787375726882])\n","Epoch 00108: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch : [108] Train loss : [0.012310599908232689] Val Score : [0.9165787375726882])\n","Epoch : [109] Train loss : [0.012717244082263537] Val Score : [0.9165787375726882])\n","Epoch : [110] Train loss : [0.014251646851854665] Val Score : [0.9165787375726882])\n","Epoch : [111] Train loss : [0.016730557328888347] Val Score : [0.9165787375726882])\n","Epoch : [112] Train loss : [0.013353820757142134] Val Score : [0.9165787375726882])\n","Epoch : [113] Train loss : [0.01371241467339652] Val Score : [0.9165787375726882])\n","Epoch : [114] Train loss : [0.015458404618714536] Val Score : [0.9165787375726882])\n","Epoch : [115] Train loss : [0.012755950114556722] Val Score : [0.9165787375726882])\n","Epoch : [116] Train loss : [0.012009492277034692] Val Score : [0.9165787375726882])\n","Epoch : [117] Train loss : [0.01239030116370746] Val Score : [0.9165787375726882])\n","Epoch : [118] Train loss : [0.013583058358303137] Val Score : [0.9165787375726882])\n","Epoch 00119: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch : [119] Train loss : [0.013129484174507005] Val Score : [0.9165787375726882])\n","Epoch : [120] Train loss : [0.012751101117048944] Val Score : [0.9165787375726882])\n","Epoch : [121] Train loss : [0.012516770511865616] Val Score : [0.9165787375726882])\n","Epoch : [122] Train loss : [0.013502994419208594] Val Score : [0.9165787375726882])\n","Epoch : [123] Train loss : [0.012333812724266733] Val Score : [0.9165787375726882])\n","Epoch : [124] Train loss : [0.013702764042786189] Val Score : [0.9165787375726882])\n","Epoch : [125] Train loss : [0.012278414996606963] Val Score : [0.9165787375726882])\n","Epoch : [126] Train loss : [0.012305644473859243] Val Score : [0.9165787375726882])\n","Epoch : [127] Train loss : [0.012368480541876383] Val Score : [0.9165787375726882])\n","Epoch : [128] Train loss : [0.012516963960868972] Val Score : [0.9165787375726882])\n","Epoch : [129] Train loss : [0.013148021485124315] Val Score : [0.9165787375726882])\n","Epoch 00130: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch : [130] Train loss : [0.012976050110799926] Val Score : [0.9165787375726882])\n","Epoch : [131] Train loss : [0.013545995844261987] Val Score : [0.9165787375726882])\n","Epoch : [132] Train loss : [0.013346167946500438] Val Score : [0.9165787375726882])\n","Epoch : [133] Train loss : [0.012063729975904738] Val Score : [0.9165787375726882])\n","Epoch : [134] Train loss : [0.012909178622066975] Val Score : [0.9165787375726882])\n","Epoch : [135] Train loss : [0.012387534603476524] Val Score : [0.9165787375726882])\n","Epoch : [136] Train loss : [0.011646192919995104] Val Score : [0.9165787375726882])\n","Epoch : [137] Train loss : [0.01434884952115161] Val Score : [0.9165787375726882])\n","Epoch : [138] Train loss : [0.01193335306431566] Val Score : [0.9165787375726882])\n","Epoch : [139] Train loss : [0.013465809236679758] Val Score : [0.9165787375726882])\n","Epoch : [140] Train loss : [0.014723616519144602] Val Score : [0.9165787375726882])\n","Epoch 00141: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch : [141] Train loss : [0.013201556434588773] Val Score : [0.9165787375726882])\n","Epoch : [142] Train loss : [0.014982483216694422] Val Score : [0.9165787375726882])\n","Epoch : [143] Train loss : [0.011989009300512927] Val Score : [0.9165787375726882])\n","Epoch : [144] Train loss : [0.012210048868187837] Val Score : [0.9165787375726882])\n","Epoch : [145] Train loss : [0.01393800348575626] Val Score : [0.9165787375726882])\n","Epoch : [146] Train loss : [0.012073702178895473] Val Score : [0.9165787375726882])\n","Epoch : [147] Train loss : [0.012356233516974109] Val Score : [0.9165787375726882])\n","Epoch : [148] Train loss : [0.012875895548079695] Val Score : [0.9165787375726882])\n","Epoch : [149] Train loss : [0.0123536650623594] Val Score : [0.9165787375726882])\n","Epoch : [150] Train loss : [0.01276241336017847] Val Score : [0.9165787375726882])\n","Epoch : [151] Train loss : [0.013377583452633448] Val Score : [0.9165787375726882])\n","Epoch 00152: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch : [152] Train loss : [0.014593644998967648] Val Score : [0.9165787375726882])\n","Epoch : [153] Train loss : [0.011863236049456256] Val Score : [0.9165787375726882])\n","Epoch : [154] Train loss : [0.013921235421938556] Val Score : [0.9165787375726882])\n","Epoch : [155] Train loss : [0.012421733300600733] Val Score : [0.9165787375726882])\n","Epoch : [156] Train loss : [0.013731538185051509] Val Score : [0.9165787375726882])\n","Epoch : [157] Train loss : [0.012499382586351462] Val Score : [0.9165787375726882])\n","Epoch : [158] Train loss : [0.013167724412466799] Val Score : [0.9165787375726882])\n","Epoch : [159] Train loss : [0.015363628576908792] Val Score : [0.9165787375726882])\n","Epoch : [160] Train loss : [0.013302450866571494] Val Score : [0.9165787375726882])\n","Epoch : [161] Train loss : [0.012624987933252538] Val Score : [0.9165787375726882])\n","Epoch : [162] Train loss : [0.012619595841637679] Val Score : [0.9165787375726882])\n","Epoch 00163: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch : [163] Train loss : [0.013445801633809294] Val Score : [0.9165787375726882])\n","Epoch : [164] Train loss : [0.014274432856057371] Val Score : [0.9165787375726882])\n","Epoch : [165] Train loss : [0.014017853087612562] Val Score : [0.9165787375726882])\n","Epoch : [166] Train loss : [0.012827361933887005] Val Score : [0.9165787375726882])\n","Epoch : [167] Train loss : [0.012698184166635786] Val Score : [0.9165787375726882])\n","Epoch : [168] Train loss : [0.012961887887545995] Val Score : [0.9165787375726882])\n","Epoch : [169] Train loss : [0.014987848832138948] Val Score : [0.9165787375726882])\n","Epoch : [170] Train loss : [0.01326310115733317] Val Score : [0.9165787375726882])\n","Epoch : [171] Train loss : [0.013375298519219671] Val Score : [0.9165787375726882])\n","Epoch : [172] Train loss : [0.013594821627650942] Val Score : [0.9165787375726882])\n","Epoch : [173] Train loss : [0.012593125392283713] Val Score : [0.9165787375726882])\n","Epoch 00174: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch : [174] Train loss : [0.011988007862653052] Val Score : [0.9165787375726882])\n","Epoch : [175] Train loss : [0.012670132065457957] Val Score : [0.9165787375726882])\n","Epoch : [176] Train loss : [0.013872109220496245] Val Score : [0.9165787375726882])\n","Epoch : [177] Train loss : [0.014409636945596762] Val Score : [0.9165787375726882])\n","Epoch : [178] Train loss : [0.012302926209356104] Val Score : [0.9165787375726882])\n","Epoch : [179] Train loss : [0.015472334277416979] Val Score : [0.9165787375726882])\n","Epoch : [180] Train loss : [0.012235694964017187] Val Score : [0.9165787375726882])\n","Epoch : [181] Train loss : [0.013447851740888186] Val Score : [0.9165787375726882])\n","Epoch : [182] Train loss : [0.012106294078486306] Val Score : [0.9165787375726882])\n","Epoch : [183] Train loss : [0.012431594277066844] Val Score : [0.9165787375726882])\n","Epoch : [184] Train loss : [0.01305107945310218] Val Score : [0.9165787375726882])\n","Epoch 00185: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch : [185] Train loss : [0.01464882040662425] Val Score : [0.9165787375726882])\n","Epoch : [186] Train loss : [0.013340108495737826] Val Score : [0.9165787375726882])\n","Epoch : [187] Train loss : [0.012271643616259098] Val Score : [0.9165787375726882])\n","Epoch : [188] Train loss : [0.011535783697451864] Val Score : [0.9165787375726882])\n","Epoch : [189] Train loss : [0.011912757929946696] Val Score : [0.9165787375726882])\n","Epoch : [190] Train loss : [0.012676367802279336] Val Score : [0.9165787375726882])\n","Epoch : [191] Train loss : [0.012217382900416851] Val Score : [0.9165787375726882])\n","Epoch : [192] Train loss : [0.013513098603912763] Val Score : [0.9165787375726882])\n","Epoch : [193] Train loss : [0.012677791661449842] Val Score : [0.9165787375726882])\n","Epoch : [194] Train loss : [0.012636694658015455] Val Score : [0.9165787375726882])\n","Epoch : [195] Train loss : [0.012461643666028976] Val Score : [0.9165787375726882])\n","Epoch 00196: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch : [196] Train loss : [0.015179070511034556] Val Score : [0.9165787375726882])\n","Epoch : [197] Train loss : [0.014466693624854088] Val Score : [0.9165787375726882])\n","Epoch : [198] Train loss : [0.012630732730031013] Val Score : [0.9165787375726882])\n","Epoch : [199] Train loss : [0.01323683320411614] Val Score : [0.9165787375726882])\n","Epoch : [200] Train loss : [0.013382431119680405] Val Score : [0.9165787375726882])\n","Epoch : [201] Train loss : [0.015481406955846719] Val Score : [0.9165787375726882])\n","Epoch : [202] Train loss : [0.011836044889475619] Val Score : [0.9165787375726882])\n","Epoch : [203] Train loss : [0.014366303437522479] Val Score : [0.9165787375726882])\n","Epoch : [204] Train loss : [0.014054000909839357] Val Score : [0.9165787375726882])\n","Epoch : [205] Train loss : [0.0136861652135849] Val Score : [0.9165787375726882])\n","Epoch : [206] Train loss : [0.015050504090530532] Val Score : [0.9165787375726882])\n","Epoch 00207: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch : [207] Train loss : [0.013752941441323076] Val Score : [0.9165787375726882])\n","Epoch : [208] Train loss : [0.013638773001730442] Val Score : [0.9165787375726882])\n","Epoch : [209] Train loss : [0.013675056264868804] Val Score : [0.9165787375726882])\n","Epoch : [210] Train loss : [0.01312926464847156] Val Score : [0.9165787375726882])\n","Epoch : [211] Train loss : [0.012827834513570582] Val Score : [0.9165787375726882])\n","Epoch : [212] Train loss : [0.013606387988797255] Val Score : [0.9165787375726882])\n","Epoch : [213] Train loss : [0.013359441155833858] Val Score : [0.9165787375726882])\n","Epoch : [214] Train loss : [0.012316309048661165] Val Score : [0.9165787375726882])\n","Epoch : [215] Train loss : [0.013419862038322858] Val Score : [0.9165787375726882])\n","Epoch : [216] Train loss : [0.012580852822533675] Val Score : [0.9165787375726882])\n","Epoch : [217] Train loss : [0.012301569006272725] Val Score : [0.9165787375726882])\n","Epoch 00218: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch : [218] Train loss : [0.012956525731299604] Val Score : [0.9165787375726882])\n","Epoch : [219] Train loss : [0.013598383670406682] Val Score : [0.9165787375726882])\n","Epoch : [220] Train loss : [0.014463083419416631] Val Score : [0.9165787375726882])\n","Epoch : [221] Train loss : [0.013801068333642823] Val Score : [0.9165787375726882])\n","Epoch : [222] Train loss : [0.012899890941168581] Val Score : [0.9165787375726882])\n","Epoch : [223] Train loss : [0.013358103909662791] Val Score : [0.9165787375726882])\n","Epoch : [224] Train loss : [0.01109836862555572] Val Score : [0.9165787375726882])\n","Epoch : [225] Train loss : [0.011980843198086535] Val Score : [0.9165787375726882])\n","Epoch : [226] Train loss : [0.011066314897366933] Val Score : [0.9165787375726882])\n","Epoch : [227] Train loss : [0.012939158960112504] Val Score : [0.9165787375726882])\n","Epoch : [228] Train loss : [0.011654839984008245] Val Score : [0.9165787375726882])\n","Epoch 00229: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch : [229] Train loss : [0.012338394432195596] Val Score : [0.9165787375726882])\n","Epoch : [230] Train loss : [0.012067304258900029] Val Score : [0.9165787375726882])\n","Epoch : [231] Train loss : [0.012191398867538996] Val Score : [0.9165787375726882])\n","Epoch : [232] Train loss : [0.01423366873392037] Val Score : [0.9165787375726882])\n","Epoch : [233] Train loss : [0.013334576306598527] Val Score : [0.9165787375726882])\n","Epoch : [234] Train loss : [0.013705909917397159] Val Score : [0.9165787375726882])\n","Epoch : [235] Train loss : [0.014079432136246137] Val Score : [0.9165787375726882])\n","Epoch : [236] Train loss : [0.013340457874749388] Val Score : [0.9165787375726882])\n","Epoch : [237] Train loss : [0.013887762890330382] Val Score : [0.9165787375726882])\n","Epoch : [238] Train loss : [0.0125826947124941] Val Score : [0.9165787375726882])\n","Epoch : [239] Train loss : [0.013298098796180316] Val Score : [0.9165787375726882])\n","Epoch 00240: reducing learning rate of group 0 to 1.9073e-08.\n","Epoch : [240] Train loss : [0.016166610377175466] Val Score : [0.9165787375726882])\n","Epoch : [241] Train loss : [0.013957623924527849] Val Score : [0.9165787375726882])\n","Epoch : [242] Train loss : [0.014830401566411768] Val Score : [0.9165787375726882])\n","Epoch : [243] Train loss : [0.013510146045259066] Val Score : [0.9165787375726882])\n","Epoch : [244] Train loss : [0.014207577066762107] Val Score : [0.9165787375726882])\n","Epoch : [245] Train loss : [0.012636202786649977] Val Score : [0.9165787375726882])\n","Epoch : [246] Train loss : [0.012438583986035414] Val Score : [0.9165787375726882])\n","Epoch : [247] Train loss : [0.013472847640514374] Val Score : [0.9165787375726882])\n","Epoch : [248] Train loss : [0.013821676905666078] Val Score : [0.9165787375726882])\n","Epoch : [249] Train loss : [0.013021138895835196] Val Score : [0.9165787375726882])\n","Epoch : [250] Train loss : [0.014408385647194726] Val Score : [0.9165787375726882])\n","Epoch : [251] Train loss : [0.012845862257693495] Val Score : [0.9165787375726882])\n","Epoch : [252] Train loss : [0.01239544911576169] Val Score : [0.9165787375726882])\n","Epoch : [253] Train loss : [0.012569581956735678] Val Score : [0.9165787375726882])\n","Epoch : [254] Train loss : [0.01335791272244283] Val Score : [0.9165787375726882])\n","Epoch : [255] Train loss : [0.014987398471151079] Val Score : [0.9165787375726882])\n","Epoch : [256] Train loss : [0.017039610472108637] Val Score : [0.9165787375726882])\n","Epoch : [257] Train loss : [0.013284787934805666] Val Score : [0.9165787375726882])\n","Epoch : [258] Train loss : [0.012735802148069655] Val Score : [0.9165787375726882])\n","Epoch : [259] Train loss : [0.013817106373608112] Val Score : [0.9165787375726882])\n","Epoch : [260] Train loss : [0.012873390423400062] Val Score : [0.9165787375726882])\n","Epoch : [261] Train loss : [0.014265774083989007] Val Score : [0.9165787375726882])\n","Epoch : [262] Train loss : [0.012553744550262178] Val Score : [0.9165787375726882])\n","Epoch : [263] Train loss : [0.011746046266385488] Val Score : [0.9165787375726882])\n","Epoch : [264] Train loss : [0.012508803712470191] Val Score : [0.9165787375726882])\n","Epoch : [265] Train loss : [0.013930800237825938] Val Score : [0.9165787375726882])\n","Epoch : [266] Train loss : [0.013508378528058529] Val Score : [0.9165787375726882])\n","Epoch : [267] Train loss : [0.013528482190200261] Val Score : [0.9165787375726882])\n","Epoch : [268] Train loss : [0.013572129820074354] Val Score : [0.9165787375726882])\n","Epoch : [269] Train loss : [0.012651801641498293] Val Score : [0.9165787375726882])\n","Epoch : [270] Train loss : [0.01430230654243912] Val Score : [0.9165787375726882])\n","Epoch : [271] Train loss : [0.011465616790311677] Val Score : [0.9165787375726882])\n","Epoch : [272] Train loss : [0.013237963164491313] Val Score : [0.9165787375726882])\n","Epoch : [273] Train loss : [0.012253195180424623] Val Score : [0.9165787375726882])\n","Epoch : [274] Train loss : [0.013886369232620512] Val Score : [0.9165787375726882])\n","Epoch : [275] Train loss : [0.011847011345837797] Val Score : [0.9165787375726882])\n","Epoch : [276] Train loss : [0.013436459670109408] Val Score : [0.9165787375726882])\n","Epoch : [277] Train loss : [0.01199345476925373] Val Score : [0.9165787375726882])\n","Epoch : [278] Train loss : [0.0133106688569699] Val Score : [0.9165787375726882])\n","Epoch : [279] Train loss : [0.013125206343829632] Val Score : [0.9165787375726882])\n","Epoch : [280] Train loss : [0.012606787628361158] Val Score : [0.9165787375726882])\n","Epoch : [281] Train loss : [0.012612052927059787] Val Score : [0.9165787375726882])\n","Epoch : [282] Train loss : [0.01258292474917003] Val Score : [0.9165787375726882])\n","Epoch : [283] Train loss : [0.0156367298747812] Val Score : [0.9165787375726882])\n","Epoch : [284] Train loss : [0.012341192524347986] Val Score : [0.9165787375726882])\n","Epoch : [285] Train loss : [0.012978903284030301] Val Score : [0.9165787375726882])\n","Epoch : [286] Train loss : [0.013139271842581885] Val Score : [0.9165787375726882])\n","Epoch : [287] Train loss : [0.012741209140845708] Val Score : [0.9165787375726882])\n","Epoch : [288] Train loss : [0.012082022481731005] Val Score : [0.9165787375726882])\n","Epoch : [289] Train loss : [0.013118239651833261] Val Score : [0.9165787375726882])\n","Epoch : [290] Train loss : [0.013833981539521898] Val Score : [0.9165787375726882])\n","Epoch : [291] Train loss : [0.013950902303414685] Val Score : [0.9165787375726882])\n","Epoch : [292] Train loss : [0.012936204139675413] Val Score : [0.9165787375726882])\n","Epoch : [293] Train loss : [0.01259353238024882] Val Score : [0.9165787375726882])\n","Epoch : [294] Train loss : [0.013143176212906837] Val Score : [0.9165787375726882])\n","Epoch : [295] Train loss : [0.014122878866536277] Val Score : [0.9165787375726882])\n","Epoch : [296] Train loss : [0.013509639272732394] Val Score : [0.9165787375726882])\n","Epoch : [297] Train loss : [0.015204238705337048] Val Score : [0.9165787375726882])\n","Epoch : [298] Train loss : [0.013008342390613896] Val Score : [0.9165787375726882])\n","Epoch : [299] Train loss : [0.012176255296383585] Val Score : [0.9165787375726882])\n","Epoch : [300] Train loss : [0.014259351018284048] Val Score : [0.9165787375726882])\n","Epoch : [301] Train loss : [0.011633292505783694] Val Score : [0.9165787375726882])\n","Epoch : [302] Train loss : [0.01684925119791712] Val Score : [0.9165787375726882])\n","Epoch : [303] Train loss : [0.013148319907486439] Val Score : [0.9165787375726882])\n","Epoch : [304] Train loss : [0.014375530715499605] Val Score : [0.9165787375726882])\n","Epoch : [305] Train loss : [0.012290249977793013] Val Score : [0.9165787375726882])\n","Epoch : [306] Train loss : [0.014195166262132781] Val Score : [0.9165787375726882])\n","Epoch : [307] Train loss : [0.015442432835698128] Val Score : [0.9165787375726882])\n","Epoch : [308] Train loss : [0.013820829668215342] Val Score : [0.9165787375726882])\n","Epoch : [309] Train loss : [0.013863392174243927] Val Score : [0.9165787375726882])\n","Epoch : [310] Train loss : [0.013745288497635297] Val Score : [0.9165787375726882])\n","Epoch : [311] Train loss : [0.012296302510159356] Val Score : [0.9165787375726882])\n","Epoch : [312] Train loss : [0.015064619747655732] Val Score : [0.9165787375726882])\n","Epoch : [313] Train loss : [0.013369325681456498] Val Score : [0.9165787375726882])\n","Epoch : [314] Train loss : [0.012630884668656759] Val Score : [0.9165787375726882])\n","Epoch : [315] Train loss : [0.01430041076881545] Val Score : [0.9165787375726882])\n","Epoch : [316] Train loss : [0.013950219377875328] Val Score : [0.9165787375726882])\n","Epoch : [317] Train loss : [0.012589721807411738] Val Score : [0.9165787375726882])\n","Epoch : [318] Train loss : [0.01443230068045003] Val Score : [0.9165787375726882])\n","Epoch : [319] Train loss : [0.013852499824549471] Val Score : [0.9165787375726882])\n","Epoch : [320] Train loss : [0.013983685656317644] Val Score : [0.9165787375726882])\n","Epoch : [321] Train loss : [0.0131800202652812] Val Score : [0.9165787375726882])\n","Epoch : [322] Train loss : [0.014466478223247188] Val Score : [0.9165787375726882])\n","Epoch : [323] Train loss : [0.012401346383350236] Val Score : [0.9165787375726882])\n","Epoch : [324] Train loss : [0.013932628557085991] Val Score : [0.9165787375726882])\n","Epoch : [325] Train loss : [0.011499606205948762] Val Score : [0.9165787375726882])\n","Epoch : [326] Train loss : [0.014536592311092786] Val Score : [0.9165787375726882])\n","Epoch : [327] Train loss : [0.014399918195392405] Val Score : [0.9165787375726882])\n","Epoch : [328] Train loss : [0.013523969799280167] Val Score : [0.9165787375726882])\n","Epoch : [329] Train loss : [0.012107369090829576] Val Score : [0.9165787375726882])\n","Epoch : [330] Train loss : [0.014313907894705023] Val Score : [0.9165787375726882])\n","Epoch : [331] Train loss : [0.011983201705983706] Val Score : [0.9165787375726882])\n","Epoch : [332] Train loss : [0.012443734732057368] Val Score : [0.9165787375726882])\n","Epoch : [333] Train loss : [0.013389577024749346] Val Score : [0.9165787375726882])\n","Epoch : [334] Train loss : [0.014821733614163739] Val Score : [0.9165787375726882])\n","Epoch : [335] Train loss : [0.0122609907495124] Val Score : [0.9165787375726882])\n","Epoch : [336] Train loss : [0.013147562476141112] Val Score : [0.9165787375726882])\n","Epoch : [337] Train loss : [0.013315962494484015] Val Score : [0.9165787375726882])\n","Epoch : [338] Train loss : [0.01528938952833414] Val Score : [0.9165787375726882])\n","Epoch : [339] Train loss : [0.011723212897777557] Val Score : [0.9165787375726882])\n","Epoch : [340] Train loss : [0.01363779032336814] Val Score : [0.9165787375726882])\n","Epoch : [341] Train loss : [0.013611665394689356] Val Score : [0.9165787375726882])\n","Epoch : [342] Train loss : [0.011603381085608686] Val Score : [0.9165787375726882])\n","Epoch : [343] Train loss : [0.013348380768937724] Val Score : [0.9165787375726882])\n","Epoch : [344] Train loss : [0.01262962059783084] Val Score : [0.9165787375726882])\n","Epoch : [345] Train loss : [0.013701133030865873] Val Score : [0.9165787375726882])\n","Epoch : [346] Train loss : [0.011764477672321456] Val Score : [0.9165787375726882])\n","Epoch : [347] Train loss : [0.012735547897006785] Val Score : [0.9165787375726882])\n","Epoch : [348] Train loss : [0.01299424615821668] Val Score : [0.9165787375726882])\n","Epoch : [349] Train loss : [0.013088097928890161] Val Score : [0.9165787375726882])\n","Epoch : [350] Train loss : [0.011662988258259637] Val Score : [0.9165787375726882])\n","Epoch : [351] Train loss : [0.011435339227318764] Val Score : [0.9165787375726882])\n","Epoch : [352] Train loss : [0.01207039225846529] Val Score : [0.9165787375726882])\n","Epoch : [353] Train loss : [0.011741000094584056] Val Score : [0.9165787375726882])\n","Epoch : [354] Train loss : [0.011796259853456701] Val Score : [0.9165787375726882])\n","Epoch : [355] Train loss : [0.012222672014364175] Val Score : [0.9165787375726882])\n","Epoch : [356] Train loss : [0.013528305371957166] Val Score : [0.9165787375726882])\n","Epoch : [357] Train loss : [0.01265739104045289] Val Score : [0.9165787375726882])\n","Epoch : [358] Train loss : [0.01332795460309301] Val Score : [0.9165787375726882])\n","Epoch : [359] Train loss : [0.013773197707320963] Val Score : [0.9165787375726882])\n","Epoch : [360] Train loss : [0.013039655717355865] Val Score : [0.9165787375726882])\n","Epoch : [361] Train loss : [0.01299154625407287] Val Score : [0.9165787375726882])\n","Epoch : [362] Train loss : [0.01337978443396943] Val Score : [0.9165787375726882])\n","Epoch : [363] Train loss : [0.012261003388890199] Val Score : [0.9165787375726882])\n","Epoch : [364] Train loss : [0.014560326002538204] Val Score : [0.9165787375726882])\n","Epoch : [365] Train loss : [0.012979664573712009] Val Score : [0.9165787375726882])\n","Epoch : [366] Train loss : [0.012184083993945802] Val Score : [0.9165787375726882])\n","Epoch : [367] Train loss : [0.014006299232797963] Val Score : [0.9165787375726882])\n","Epoch : [368] Train loss : [0.012429523414799146] Val Score : [0.9165787375726882])\n","Epoch : [369] Train loss : [0.01271458515631301] Val Score : [0.9165787375726882])\n","Epoch : [370] Train loss : [0.01361383723893336] Val Score : [0.9165787375726882])\n","Epoch : [371] Train loss : [0.011795328397836004] Val Score : [0.9165787375726882])\n","Epoch : [372] Train loss : [0.01172304353011506] Val Score : [0.9165787375726882])\n","Epoch : [373] Train loss : [0.015001601406506129] Val Score : [0.9165787375726882])\n","Epoch : [374] Train loss : [0.013639732929212707] Val Score : [0.9165787375726882])\n","Epoch : [375] Train loss : [0.012670643760689668] Val Score : [0.9165787375726882])\n","Epoch : [376] Train loss : [0.013419260270893574] Val Score : [0.9165787375726882])\n","Epoch : [377] Train loss : [0.01413949073425361] Val Score : [0.9165787375726882])\n","Epoch : [378] Train loss : [0.01211375610104629] Val Score : [0.9165787375726882])\n","Epoch : [379] Train loss : [0.013591454364359379] Val Score : [0.9165787375726882])\n","Epoch : [380] Train loss : [0.012592374746288573] Val Score : [0.9165787375726882])\n","Epoch : [381] Train loss : [0.01386846655181476] Val Score : [0.9165787375726882])\n","Epoch : [382] Train loss : [0.014215565685714995] Val Score : [0.9165787375726882])\n","Epoch : [383] Train loss : [0.014272243715822697] Val Score : [0.9165787375726882])\n","Epoch : [384] Train loss : [0.013837960947837149] Val Score : [0.9165787375726882])\n","Epoch : [385] Train loss : [0.012924268043466977] Val Score : [0.9165787375726882])\n","Epoch : [386] Train loss : [0.013077899414513792] Val Score : [0.9165787375726882])\n","Epoch : [387] Train loss : [0.012724490304078375] Val Score : [0.9165787375726882])\n","Epoch : [388] Train loss : [0.013051980308123998] Val Score : [0.9165787375726882])\n","Epoch : [389] Train loss : [0.013864808449787753] Val Score : [0.9165787375726882])\n","Epoch : [390] Train loss : [0.013651537708938122] Val Score : [0.9165787375726882])\n","Epoch : [391] Train loss : [0.013485119145895754] Val Score : [0.9165787375726882])\n","Epoch : [392] Train loss : [0.013441497992191995] Val Score : [0.9165787375726882])\n","Epoch : [393] Train loss : [0.012568956107965537] Val Score : [0.9165787375726882])\n","Epoch : [394] Train loss : [0.01189312884317977] Val Score : [0.9165787375726882])\n","Epoch : [395] Train loss : [0.011966222764125891] Val Score : [0.9165787375726882])\n","Epoch : [396] Train loss : [0.012540985963174276] Val Score : [0.9165787375726882])\n","Epoch : [397] Train loss : [0.012431268846350057] Val Score : [0.9165787375726882])\n","Epoch : [398] Train loss : [0.012410711230976241] Val Score : [0.9165787375726882])\n","Epoch : [399] Train loss : [0.014588781499436923] Val Score : [0.9165787375726882])\n"]}],"source":["model = nn.DataParallel(AutoEncoder())\n","model.eval()\n","\n","# optim 패키지를 사용하여 모델의 가중치를 갱신할 optimizer를 정의합니다.\n","optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n","# 학습률 개선 scheduler, patience번 정체되면 학습률 factor와 곱한다. \n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n","\n","trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n","trainer.fit()"]},{"cell_type":"markdown","source":["### train 데이터를 예측"],"metadata":{"id":"HudNXB80eDDx"}},{"cell_type":"code","source":["# 학습된 내용 불러오기\n","model = AutoEncoder()\n","model.load_state_dict(torch.load('./best_model.pth'))\n","model = nn.DataParallel(model)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E5jCXae_eKy4","executionInfo":{"status":"ok","timestamp":1658830120221,"user_tz":-540,"elapsed":453,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"48a76cb5-d152-41bb-d323-7ede33ad9a46"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataParallel(\n","  (module): AutoEncoder(\n","    (Encoder): Sequential(\n","      (0): Linear(in_features=30, out_features=64, bias=True)\n","      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): PReLU(num_parameters=1)\n","      (3): Linear(in_features=64, out_features=128, bias=True)\n","      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): PReLU(num_parameters=1)\n","    )\n","    (Decoder): Sequential(\n","      (0): Linear(in_features=128, out_features=64, bias=True)\n","      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): PReLU(num_parameters=1)\n","      (3): Linear(in_features=64, out_features=30, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["train_loader2 = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=2)"],"metadata":{"id":"8ZE5Ll2aeSDC","executionInfo":{"status":"ok","timestamp":1658830121605,"user_tz":-540,"elapsed":5,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def prediction(model, thr, test_loader, device):\n","    model.to(device)\n","    model.eval()\n","    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","    pred = []\n","    with torch.no_grad():\n","        for x in iter(test_loader):\n","            x = x.float().to(device)\n","            \n","            _x = model(x)\n","            \n","            diff = cos(x, _x).cpu().tolist()\n","            batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n","            pred += batch_pred\n","    return pred"],"metadata":{"id":"zFK4FmmXeha4","executionInfo":{"status":"ok","timestamp":1658830122717,"user_tz":-540,"elapsed":3,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["train_df2 = train_df\n","preds = prediction(model,0.95,train_loader2,device)"],"metadata":{"id":"54rq9_YDeiDA","executionInfo":{"status":"ok","timestamp":1658830125745,"user_tz":-540,"elapsed":1518,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["train_df2['Class'] = preds"],"metadata":{"id":"Su36pZ3Dew1f","executionInfo":{"status":"ok","timestamp":1658830127821,"user_tz":-540,"elapsed":451,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["train_df2_normal = train_df2[train_df['Class']==0]"],"metadata":{"id":"qAwKO0x5fe5D","executionInfo":{"status":"ok","timestamp":1658830129059,"user_tz":-540,"elapsed":4,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["train_df2_normal = train_df2_normal.drop(columns=['Class'])"],"metadata":{"id":"ilsxkLRie5ni","executionInfo":{"status":"ok","timestamp":1658830131032,"user_tz":-540,"elapsed":470,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["### 예측한 train_df2 로 모델 다시 구성"],"metadata":{"id":"oycJjBC0fL8r"}},{"cell_type":"code","source":["train_dataset2 = MyDataset(df=train_df2_normal, eval_mode=False)\n","train_loader2 = DataLoader(train_dataset2, batch_size=BS, shuffle=True, num_workers=2)"],"metadata":{"id":"Ei8YtWB9fYio","executionInfo":{"status":"ok","timestamp":1658830134451,"user_tz":-540,"elapsed":686,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["class Trainer():\n","    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.scheduler = scheduler\n","        self.device = device\n","        # Loss Function\n","        self.criterion = nn.L1Loss().to(self.device)\n","        \n","    def fit(self, ):\n","        self.model.to(self.device)\n","        best_score = 0\n","        for epoch in range(EPOCHS):\n","            self.model.train()\n","            train_loss = []\n","            for x in iter(self.train_loader):\n","                x = x.float().to(self.device)\n","                # 역전파 단계 전에, optimizer 객체를 사용하여 (모델의 학습 가능한 가중치인) 갱신할\n","                # 변수들에 대한 모든 변화도(gradient)를 0으로 만듭니다. 이렇게 하는 이유는 기본적으로 \n","                # .backward()를 호출할 때마다 변화도가 버퍼(buffer)에 (덮어쓰지 않고) 누적되기\n","                # 때문입니다. 더 자세한 내용은 torch.autograd.backward에 대한 문서를 참조하세요.\n","                self.optimizer.zero_grad()\n","\n","                # AutoEncoder 통과한 예측값\n","                _x = self.model(x)\n","                loss = self.criterion(x, _x)\n","\n","                # 역전파 단계: 모델의 매개변수들에 대한 손실의 변화도를 계산합니다.\n","                loss.backward()\n","                # optimizer의 step 함수를 호출하면 매개변수가 갱신됩니다.\n","                self.optimizer.step()\n","\n","                train_loss.append(loss.item())\n","\n","            score = self.validation(self.model, 0.95)\n","            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n","\n","            if self.scheduler is not None:\n","                self.scheduler.step(score)\n","\n","            if best_score < score:\n","                best_score = score\n","                torch.save(model.module.state_dict(), './best_model2.pth', _use_new_zipfile_serialization=False)\n","    \n","    def validation(self, eval_model, thr):\n","        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","        #  model.eval()는 이런 layer들의 동작을 inference(eval) mode로 바꿔준다는 목적\n","        eval_model.eval()\n","        pred = []\n","        true = []\n","        # torch.no_grad()의 주된 목적은 autograd(자동으로 gradient를 트래킹)를 끔으로써 메모리 사용량을 줄이고 연산 속도를 높히기 위함\n","        with torch.no_grad():\n","            for x, y in iter(self.val_loader):\n","                x = x.float().to(self.device)\n","\n","                _x = self.model(x)\n","                diff = cos(x, _x).cpu().tolist()\n","                #유사도 0.95보다 작은것은 이상거래 1, 아닌 것은 정상거래 0\n","                batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n","                pred += batch_pred\n","                true += y.tolist()\n","\n","        return f1_score(true, pred, average='macro')"],"metadata":{"id":"duNXoMevfu1e","executionInfo":{"status":"ok","timestamp":1658830135440,"user_tz":-540,"elapsed":4,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["model2 = nn.DataParallel(AutoEncoder())\n","model2.eval()\n","\n","# optim 패키지를 사용하여 모델의 가중치를 갱신할 optimizer를 정의합니다.\n","optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n","# 학습률 개선 scheduler, patience번 정체되면 학습률 factor와 곱한다. \n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n","\n","trainer2 = Trainer(model, optimizer, train_loader2, val_loader, scheduler, device)\n","trainer2.fit()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CeBzbbaUfSBU","executionInfo":{"status":"ok","timestamp":1658830763522,"user_tz":-540,"elapsed":608289,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"3f8350e7-9bc6-43f7-c5b3-0f562e6accdf"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : [0] Train loss : [0.1290849239698478] Val Score : [0.9165787375726882])\n","Epoch : [1] Train loss : [0.07511859600033079] Val Score : [0.9165787375726882])\n","Epoch : [2] Train loss : [0.05358704924583435] Val Score : [0.9165787375726882])\n","Epoch : [3] Train loss : [0.04091528217707362] Val Score : [0.9165787375726882])\n","Epoch : [4] Train loss : [0.039077892899513245] Val Score : [0.9165787375726882])\n","Epoch : [5] Train loss : [0.037179536053112576] Val Score : [0.9165787375726882])\n","Epoch : [6] Train loss : [0.035773011722735] Val Score : [0.9165787375726882])\n","Epoch : [7] Train loss : [0.03715585385050092] Val Score : [0.9165787375726882])\n","Epoch : [8] Train loss : [0.03896196239760944] Val Score : [0.9165787375726882])\n","Epoch : [9] Train loss : [0.03535343334078789] Val Score : [0.9165787375726882])\n","Epoch : [10] Train loss : [0.03218426076429231] Val Score : [0.9165787375726882])\n","Epoch : [11] Train loss : [0.03373293285923345] Val Score : [0.9165787375726882])\n","Epoch 00012: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch : [12] Train loss : [0.028399247942226275] Val Score : [0.9165787375726882])\n","Epoch : [13] Train loss : [0.025118045242769376] Val Score : [0.9165787375726882])\n","Epoch : [14] Train loss : [0.0253931496824537] Val Score : [0.9165787375726882])\n","Epoch : [15] Train loss : [0.026356043027979986] Val Score : [0.9165787375726882])\n","Epoch : [16] Train loss : [0.027294805805597986] Val Score : [0.9165787375726882])\n","Epoch : [17] Train loss : [0.025149122944899967] Val Score : [0.9165787375726882])\n","Epoch : [18] Train loss : [0.024730252900293896] Val Score : [0.9165787375726882])\n","Epoch : [19] Train loss : [0.022778316267899106] Val Score : [0.9165787375726882])\n","Epoch : [20] Train loss : [0.027610328314559802] Val Score : [0.9165787375726882])\n","Epoch : [21] Train loss : [0.027110659650393894] Val Score : [0.9165787375726882])\n","Epoch : [22] Train loss : [0.02513794627572809] Val Score : [0.9165787375726882])\n","Epoch 00023: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch : [23] Train loss : [0.023400932816522464] Val Score : [0.9165787375726882])\n","Epoch : [24] Train loss : [0.023542160168290138] Val Score : [0.9165787375726882])\n","Epoch : [25] Train loss : [0.021819952875375748] Val Score : [0.9165787375726882])\n","Epoch : [26] Train loss : [0.023902494460344315] Val Score : [0.9165787375726882])\n","Epoch : [27] Train loss : [0.018818043438451632] Val Score : [0.9165787375726882])\n","Epoch : [28] Train loss : [0.02027168364397117] Val Score : [0.9165787375726882])\n","Epoch : [29] Train loss : [0.02068044404898371] Val Score : [0.9165787375726882])\n","Epoch : [30] Train loss : [0.02060582408947604] Val Score : [0.9165787375726882])\n","Epoch : [31] Train loss : [0.02048614222024168] Val Score : [0.9165787375726882])\n","Epoch : [32] Train loss : [0.021900071097271784] Val Score : [0.9165787375726882])\n","Epoch : [33] Train loss : [0.021876744659883634] Val Score : [0.9165787375726882])\n","Epoch 00034: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch : [34] Train loss : [0.019405657957707132] Val Score : [0.9165787375726882])\n","Epoch : [35] Train loss : [0.018578352938805307] Val Score : [0.9165787375726882])\n","Epoch : [36] Train loss : [0.017633458599448204] Val Score : [0.9165787375726882])\n","Epoch : [37] Train loss : [0.017711198755673] Val Score : [0.9165787375726882])\n","Epoch : [38] Train loss : [0.01948508314256157] Val Score : [0.9165787375726882])\n","Epoch : [39] Train loss : [0.016350930157516683] Val Score : [0.9165787375726882])\n","Epoch : [40] Train loss : [0.01738070816333805] Val Score : [0.9165787375726882])\n","Epoch : [41] Train loss : [0.015953596282218183] Val Score : [0.9165787375726882])\n","Epoch : [42] Train loss : [0.016741664414959296] Val Score : [0.9165787375726882])\n","Epoch : [43] Train loss : [0.0178041649716241] Val Score : [0.9165787375726882])\n","Epoch : [44] Train loss : [0.01612687643085207] Val Score : [0.9165787375726882])\n","Epoch 00045: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch : [45] Train loss : [0.015102211385965347] Val Score : [0.9165787375726882])\n","Epoch : [46] Train loss : [0.01697112140910966] Val Score : [0.9165787375726882])\n","Epoch : [47] Train loss : [0.01687494572252035] Val Score : [0.9165787375726882])\n","Epoch : [48] Train loss : [0.01617535123867648] Val Score : [0.9165787375726882])\n","Epoch : [49] Train loss : [0.014162321308893817] Val Score : [0.9165787375726882])\n","Epoch : [50] Train loss : [0.017956776677497795] Val Score : [0.9165787375726882])\n","Epoch : [51] Train loss : [0.0158508654151644] Val Score : [0.9165787375726882])\n","Epoch : [52] Train loss : [0.016001198440790176] Val Score : [0.9165787375726882])\n","Epoch : [53] Train loss : [0.014602701711867536] Val Score : [0.9165787375726882])\n","Epoch : [54] Train loss : [0.016778459905513694] Val Score : [0.9165787375726882])\n","Epoch : [55] Train loss : [0.01485267108572381] Val Score : [0.9165787375726882])\n","Epoch 00056: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch : [56] Train loss : [0.012973122431763582] Val Score : [0.9165787375726882])\n","Epoch : [57] Train loss : [0.012935732225222247] Val Score : [0.9165787375726882])\n","Epoch : [58] Train loss : [0.013241763891918319] Val Score : [0.9165787375726882])\n","Epoch : [59] Train loss : [0.014667127813611711] Val Score : [0.9165787375726882])\n","Epoch : [60] Train loss : [0.014577984011598996] Val Score : [0.9165787375726882])\n","Epoch : [61] Train loss : [0.01510868767010314] Val Score : [0.9165787375726882])\n","Epoch : [62] Train loss : [0.015125719963439874] Val Score : [0.9165787375726882])\n","Epoch : [63] Train loss : [0.013054157474211283] Val Score : [0.9165787375726882])\n","Epoch : [64] Train loss : [0.014662296777325017] Val Score : [0.9165787375726882])\n","Epoch : [65] Train loss : [0.01482898582305227] Val Score : [0.9165787375726882])\n","Epoch : [66] Train loss : [0.015401321862425123] Val Score : [0.9165787375726882])\n","Epoch 00067: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch : [67] Train loss : [0.014677050124321665] Val Score : [0.9165787375726882])\n","Epoch : [68] Train loss : [0.013693934971732753] Val Score : [0.9165787375726882])\n","Epoch : [69] Train loss : [0.016141719184815884] Val Score : [0.9165787375726882])\n","Epoch : [70] Train loss : [0.011705327246870314] Val Score : [0.9165787375726882])\n","Epoch : [71] Train loss : [0.011932234545903546] Val Score : [0.9165787375726882])\n","Epoch : [72] Train loss : [0.013656173699668475] Val Score : [0.9165787375726882])\n","Epoch : [73] Train loss : [0.014361064348902022] Val Score : [0.9165787375726882])\n","Epoch : [74] Train loss : [0.01567215844988823] Val Score : [0.9165787375726882])\n","Epoch : [75] Train loss : [0.013548922991114003] Val Score : [0.9165787375726882])\n","Epoch : [76] Train loss : [0.01350712776184082] Val Score : [0.9165787375726882])\n","Epoch : [77] Train loss : [0.016425040949668204] Val Score : [0.9165787375726882])\n","Epoch 00078: reducing learning rate of group 0 to 7.8125e-05.\n","Epoch : [78] Train loss : [0.013027212715574674] Val Score : [0.9165787375726882])\n","Epoch : [79] Train loss : [0.015884512902370522] Val Score : [0.9165787375726882])\n","Epoch : [80] Train loss : [0.01474548184445926] Val Score : [0.9165787375726882])\n","Epoch : [81] Train loss : [0.014335366365100657] Val Score : [0.9165787375726882])\n","Epoch : [82] Train loss : [0.01355189031788281] Val Score : [0.9165787375726882])\n","Epoch : [83] Train loss : [0.013866840861737728] Val Score : [0.9165787375726882])\n","Epoch : [84] Train loss : [0.012605354988149233] Val Score : [0.9165787375726882])\n","Epoch : [85] Train loss : [0.014567392346050059] Val Score : [0.9165787375726882])\n","Epoch : [86] Train loss : [0.014788481806005751] Val Score : [0.9165787375726882])\n","Epoch : [87] Train loss : [0.013655793054827623] Val Score : [0.9165787375726882])\n","Epoch : [88] Train loss : [0.014786082586007459] Val Score : [0.9165787375726882])\n","Epoch 00089: reducing learning rate of group 0 to 3.9063e-05.\n","Epoch : [89] Train loss : [0.014680749337588037] Val Score : [0.9165787375726882])\n","Epoch : [90] Train loss : [0.012757622769900731] Val Score : [0.9165787375726882])\n","Epoch : [91] Train loss : [0.0135826493746468] Val Score : [0.9165787375726882])\n","Epoch : [92] Train loss : [0.016112811331238066] Val Score : [0.9165787375726882])\n","Epoch : [93] Train loss : [0.011726812193436282] Val Score : [0.9165787375726882])\n","Epoch : [94] Train loss : [0.013371000731629985] Val Score : [0.9165787375726882])\n","Epoch : [95] Train loss : [0.01653755203421627] Val Score : [0.9165787375726882])\n","Epoch : [96] Train loss : [0.012477145796375615] Val Score : [0.9165787375726882])\n","Epoch : [97] Train loss : [0.013503323841307844] Val Score : [0.9165787375726882])\n","Epoch : [98] Train loss : [0.012672443741134234] Val Score : [0.9165787375726882])\n","Epoch : [99] Train loss : [0.015021732210048608] Val Score : [0.9165787375726882])\n","Epoch 00100: reducing learning rate of group 0 to 1.9531e-05.\n","Epoch : [100] Train loss : [0.012293499096163682] Val Score : [0.9165787375726882])\n","Epoch : [101] Train loss : [0.012852683796414308] Val Score : [0.9165787375726882])\n","Epoch : [102] Train loss : [0.01155270662690912] Val Score : [0.9165787375726882])\n","Epoch : [103] Train loss : [0.014360562765172549] Val Score : [0.9165787375726882])\n","Epoch : [104] Train loss : [0.012594497762620449] Val Score : [0.9165787375726882])\n","Epoch : [105] Train loss : [0.012664480400936944] Val Score : [0.9165787375726882])\n","Epoch : [106] Train loss : [0.013553808443248272] Val Score : [0.9165787375726882])\n","Epoch : [107] Train loss : [0.012974407923008715] Val Score : [0.9165787375726882])\n","Epoch : [108] Train loss : [0.014681641810706683] Val Score : [0.9165787375726882])\n","Epoch : [109] Train loss : [0.016029721392052516] Val Score : [0.9165787375726882])\n","Epoch : [110] Train loss : [0.011799527864371027] Val Score : [0.9165787375726882])\n","Epoch 00111: reducing learning rate of group 0 to 9.7656e-06.\n","Epoch : [111] Train loss : [0.015914956240781715] Val Score : [0.9165787375726882])\n","Epoch : [112] Train loss : [0.013410119605915887] Val Score : [0.9165787375726882])\n","Epoch : [113] Train loss : [0.013157670652227742] Val Score : [0.9165787375726882])\n","Epoch : [114] Train loss : [0.01360079792461225] Val Score : [0.9165787375726882])\n","Epoch : [115] Train loss : [0.011501811976943697] Val Score : [0.9165787375726882])\n","Epoch : [116] Train loss : [0.013051609508693218] Val Score : [0.9165787375726882])\n","Epoch : [117] Train loss : [0.014429920219949313] Val Score : [0.9165787375726882])\n","Epoch : [118] Train loss : [0.013363366414393698] Val Score : [0.9165787375726882])\n","Epoch : [119] Train loss : [0.013592935699437345] Val Score : [0.9165787375726882])\n","Epoch : [120] Train loss : [0.013550843112170696] Val Score : [0.9165787375726882])\n","Epoch : [121] Train loss : [0.013729783440274852] Val Score : [0.9165787375726882])\n","Epoch 00122: reducing learning rate of group 0 to 4.8828e-06.\n","Epoch : [122] Train loss : [0.013936060480773449] Val Score : [0.9165787375726882])\n","Epoch : [123] Train loss : [0.013601612565772874] Val Score : [0.9165787375726882])\n","Epoch : [124] Train loss : [0.012691321915813856] Val Score : [0.9165787375726882])\n","Epoch : [125] Train loss : [0.016007793002894947] Val Score : [0.9165787375726882])\n","Epoch : [126] Train loss : [0.013681238650211267] Val Score : [0.9165787375726882])\n","Epoch : [127] Train loss : [0.011741889507642813] Val Score : [0.9165787375726882])\n","Epoch : [128] Train loss : [0.014320471856210912] Val Score : [0.9165787375726882])\n","Epoch : [129] Train loss : [0.011901080342275756] Val Score : [0.9165787375726882])\n","Epoch : [130] Train loss : [0.013434954386736666] Val Score : [0.9165787375726882])\n","Epoch : [131] Train loss : [0.01222190447151661] Val Score : [0.9165787375726882])\n","Epoch : [132] Train loss : [0.01296535081097058] Val Score : [0.9165787375726882])\n","Epoch 00133: reducing learning rate of group 0 to 2.4414e-06.\n","Epoch : [133] Train loss : [0.014168102693344866] Val Score : [0.9165787375726882])\n","Epoch : [134] Train loss : [0.01293436358017581] Val Score : [0.9165787375726882])\n","Epoch : [135] Train loss : [0.01286505109497479] Val Score : [0.9165787375726882])\n","Epoch : [136] Train loss : [0.013384369468050343] Val Score : [0.9165787375726882])\n","Epoch : [137] Train loss : [0.011732010703001703] Val Score : [0.9165787375726882])\n","Epoch : [138] Train loss : [0.013907260394522123] Val Score : [0.9165787375726882])\n","Epoch : [139] Train loss : [0.014623077719339303] Val Score : [0.9165787375726882])\n","Epoch : [140] Train loss : [0.014350645643259798] Val Score : [0.9165787375726882])\n","Epoch : [141] Train loss : [0.01370226511997836] Val Score : [0.9165787375726882])\n","Epoch : [142] Train loss : [0.013402397478265422] Val Score : [0.9165787375726882])\n","Epoch : [143] Train loss : [0.01323849827583347] Val Score : [0.9165787375726882])\n","Epoch 00144: reducing learning rate of group 0 to 1.2207e-06.\n","Epoch : [144] Train loss : [0.012348444201052189] Val Score : [0.9165787375726882])\n","Epoch : [145] Train loss : [0.013836664812905448] Val Score : [0.9165787375726882])\n","Epoch : [146] Train loss : [0.012838916853070259] Val Score : [0.9165787375726882])\n","Epoch : [147] Train loss : [0.01309887891901391] Val Score : [0.9165787375726882])\n","Epoch : [148] Train loss : [0.015067511504249913] Val Score : [0.9165787375726882])\n","Epoch : [149] Train loss : [0.013554277696779795] Val Score : [0.9165787375726882])\n","Epoch : [150] Train loss : [0.012805350523974215] Val Score : [0.9165787375726882])\n","Epoch : [151] Train loss : [0.011509585460381848] Val Score : [0.9165787375726882])\n","Epoch : [152] Train loss : [0.014684525052351611] Val Score : [0.9165787375726882])\n","Epoch : [153] Train loss : [0.013331869351012366] Val Score : [0.9165787375726882])\n","Epoch : [154] Train loss : [0.014658356883696147] Val Score : [0.9165787375726882])\n","Epoch 00155: reducing learning rate of group 0 to 6.1035e-07.\n","Epoch : [155] Train loss : [0.013031930130507265] Val Score : [0.9165787375726882])\n","Epoch : [156] Train loss : [0.01572525634297303] Val Score : [0.9165787375726882])\n","Epoch : [157] Train loss : [0.011843959135668618] Val Score : [0.9165787375726882])\n","Epoch : [158] Train loss : [0.012863800328757082] Val Score : [0.9165787375726882])\n","Epoch : [159] Train loss : [0.013422508058803422] Val Score : [0.9165787375726882])\n","Epoch : [160] Train loss : [0.014394693209656648] Val Score : [0.9165787375726882])\n","Epoch : [161] Train loss : [0.015004007145762444] Val Score : [0.9165787375726882])\n","Epoch : [162] Train loss : [0.013010651538414615] Val Score : [0.9165787375726882])\n","Epoch : [163] Train loss : [0.012097312004438468] Val Score : [0.9165787375726882])\n","Epoch : [164] Train loss : [0.01341915742627212] Val Score : [0.9165787375726882])\n","Epoch : [165] Train loss : [0.013652361264186246] Val Score : [0.9165787375726882])\n","Epoch 00166: reducing learning rate of group 0 to 3.0518e-07.\n","Epoch : [166] Train loss : [0.014014373134289469] Val Score : [0.9165787375726882])\n","Epoch : [167] Train loss : [0.012482033111155033] Val Score : [0.9165787375726882])\n","Epoch : [168] Train loss : [0.012821279865290438] Val Score : [0.9165787375726882])\n","Epoch : [169] Train loss : [0.01418563976351704] Val Score : [0.9165787375726882])\n","Epoch : [170] Train loss : [0.012435353361070156] Val Score : [0.9165787375726882])\n","Epoch : [171] Train loss : [0.011244556600494044] Val Score : [0.9165787375726882])\n","Epoch : [172] Train loss : [0.013334370351263456] Val Score : [0.9165787375726882])\n","Epoch : [173] Train loss : [0.014196957993720258] Val Score : [0.9165787375726882])\n","Epoch : [174] Train loss : [0.013323114785764898] Val Score : [0.9165787375726882])\n","Epoch : [175] Train loss : [0.013307513003902776] Val Score : [0.9165787375726882])\n","Epoch : [176] Train loss : [0.013783196519528116] Val Score : [0.9165787375726882])\n","Epoch 00177: reducing learning rate of group 0 to 1.5259e-07.\n","Epoch : [177] Train loss : [0.01472215833408492] Val Score : [0.9165787375726882])\n","Epoch : [178] Train loss : [0.014628790185919829] Val Score : [0.9165787375726882])\n","Epoch : [179] Train loss : [0.012758380467338222] Val Score : [0.9165787375726882])\n","Epoch : [180] Train loss : [0.01452406495809555] Val Score : [0.9165787375726882])\n","Epoch : [181] Train loss : [0.013640012059892927] Val Score : [0.9165787375726882])\n","Epoch : [182] Train loss : [0.01252486543463809] Val Score : [0.9165787375726882])\n","Epoch : [183] Train loss : [0.013079199008643627] Val Score : [0.9165787375726882])\n","Epoch : [184] Train loss : [0.011505195471857275] Val Score : [0.9165787375726882])\n","Epoch : [185] Train loss : [0.014670937455126218] Val Score : [0.9165787375726882])\n","Epoch : [186] Train loss : [0.01345931033470801] Val Score : [0.9165787375726882])\n","Epoch : [187] Train loss : [0.014581854854311262] Val Score : [0.9165787375726882])\n","Epoch 00188: reducing learning rate of group 0 to 7.6294e-08.\n","Epoch : [188] Train loss : [0.013063148196254457] Val Score : [0.9165787375726882])\n","Epoch : [189] Train loss : [0.012782650600586618] Val Score : [0.9165787375726882])\n","Epoch : [190] Train loss : [0.01386017698262419] Val Score : [0.9165787375726882])\n","Epoch : [191] Train loss : [0.011977042337613446] Val Score : [0.9165787375726882])\n","Epoch : [192] Train loss : [0.012874121245528971] Val Score : [0.9165787375726882])\n","Epoch : [193] Train loss : [0.012950234514261996] Val Score : [0.9165787375726882])\n","Epoch : [194] Train loss : [0.014247558212706022] Val Score : [0.9165787375726882])\n","Epoch : [195] Train loss : [0.013785401359200478] Val Score : [0.9165787375726882])\n","Epoch : [196] Train loss : [0.011760201837335314] Val Score : [0.9165787375726882])\n","Epoch : [197] Train loss : [0.014666041093213218] Val Score : [0.9165787375726882])\n","Epoch : [198] Train loss : [0.014776902805481638] Val Score : [0.9165787375726882])\n","Epoch 00199: reducing learning rate of group 0 to 3.8147e-08.\n","Epoch : [199] Train loss : [0.013551545994622367] Val Score : [0.9165787375726882])\n","Epoch : [200] Train loss : [0.014059936228607382] Val Score : [0.9165787375726882])\n","Epoch : [201] Train loss : [0.013507519316460406] Val Score : [0.9165787375726882])\n","Epoch : [202] Train loss : [0.015656939574650357] Val Score : [0.9165787375726882])\n","Epoch : [203] Train loss : [0.012200706771441869] Val Score : [0.9165787375726882])\n","Epoch : [204] Train loss : [0.012463086417743139] Val Score : [0.9165787375726882])\n","Epoch : [205] Train loss : [0.012962347428713526] Val Score : [0.9165787375726882])\n","Epoch : [206] Train loss : [0.012008948118558951] Val Score : [0.9165787375726882])\n","Epoch : [207] Train loss : [0.014707798271306924] Val Score : [0.9165787375726882])\n","Epoch : [208] Train loss : [0.015672565570899417] Val Score : [0.9165787375726882])\n","Epoch : [209] Train loss : [0.013614312346492494] Val Score : [0.9165787375726882])\n","Epoch 00210: reducing learning rate of group 0 to 1.9073e-08.\n","Epoch : [210] Train loss : [0.014139989390969276] Val Score : [0.9165787375726882])\n","Epoch : [211] Train loss : [0.012596893257328443] Val Score : [0.9165787375726882])\n","Epoch : [212] Train loss : [0.013498694902019841] Val Score : [0.9165787375726882])\n","Epoch : [213] Train loss : [0.013646821358374186] Val Score : [0.9165787375726882])\n","Epoch : [214] Train loss : [0.012233377434313297] Val Score : [0.9165787375726882])\n","Epoch : [215] Train loss : [0.013478471232312066] Val Score : [0.9165787375726882])\n","Epoch : [216] Train loss : [0.013689291530421801] Val Score : [0.9165787375726882])\n","Epoch : [217] Train loss : [0.013494273514619895] Val Score : [0.9165787375726882])\n","Epoch : [218] Train loss : [0.015284174254962377] Val Score : [0.9165787375726882])\n","Epoch : [219] Train loss : [0.014774799213877745] Val Score : [0.9165787375726882])\n","Epoch : [220] Train loss : [0.012871203544948782] Val Score : [0.9165787375726882])\n","Epoch : [221] Train loss : [0.013998868609113353] Val Score : [0.9165787375726882])\n","Epoch : [222] Train loss : [0.012692005107445377] Val Score : [0.9165787375726882])\n","Epoch : [223] Train loss : [0.013891988034759249] Val Score : [0.9165787375726882])\n","Epoch : [224] Train loss : [0.01455630175769329] Val Score : [0.9165787375726882])\n","Epoch : [225] Train loss : [0.012389307442520345] Val Score : [0.9165787375726882])\n","Epoch : [226] Train loss : [0.01507913161601339] Val Score : [0.9165787375726882])\n","Epoch : [227] Train loss : [0.012676400797707694] Val Score : [0.9165787375726882])\n","Epoch : [228] Train loss : [0.014562145141618592] Val Score : [0.9165787375726882])\n","Epoch : [229] Train loss : [0.01380700817597764] Val Score : [0.9165787375726882])\n","Epoch : [230] Train loss : [0.013456541512693678] Val Score : [0.9165787375726882])\n","Epoch : [231] Train loss : [0.01368372474930116] Val Score : [0.9165787375726882])\n","Epoch : [232] Train loss : [0.013800369442573615] Val Score : [0.9165787375726882])\n","Epoch : [233] Train loss : [0.012199919005589826] Val Score : [0.9165787375726882])\n","Epoch : [234] Train loss : [0.014265397297484534] Val Score : [0.9165787375726882])\n","Epoch : [235] Train loss : [0.015420754706220967] Val Score : [0.9165787375726882])\n","Epoch : [236] Train loss : [0.016007531567343643] Val Score : [0.9165787375726882])\n","Epoch : [237] Train loss : [0.015424247964152269] Val Score : [0.9165787375726882])\n","Epoch : [238] Train loss : [0.013330193369516305] Val Score : [0.9165787375726882])\n","Epoch : [239] Train loss : [0.013638246272291456] Val Score : [0.9165787375726882])\n","Epoch : [240] Train loss : [0.013660407092954432] Val Score : [0.9165787375726882])\n","Epoch : [241] Train loss : [0.013901338114270143] Val Score : [0.9165787375726882])\n","Epoch : [242] Train loss : [0.012551625791404928] Val Score : [0.9165787375726882])\n","Epoch : [243] Train loss : [0.0131159991558109] Val Score : [0.9165787375726882])\n","Epoch : [244] Train loss : [0.013304719834455423] Val Score : [0.9165787375726882])\n","Epoch : [245] Train loss : [0.013056970733617033] Val Score : [0.9165787375726882])\n","Epoch : [246] Train loss : [0.015263280565185207] Val Score : [0.9165787375726882])\n","Epoch : [247] Train loss : [0.012509753927588463] Val Score : [0.9165787375726882])\n","Epoch : [248] Train loss : [0.013772711689983095] Val Score : [0.9165787375726882])\n","Epoch : [249] Train loss : [0.012355668869401728] Val Score : [0.9165787375726882])\n","Epoch : [250] Train loss : [0.012198223200227534] Val Score : [0.9165787375726882])\n","Epoch : [251] Train loss : [0.013325514271855354] Val Score : [0.9165787375726882])\n","Epoch : [252] Train loss : [0.014748160195137774] Val Score : [0.9165787375726882])\n","Epoch : [253] Train loss : [0.013900330423244409] Val Score : [0.9165787375726882])\n","Epoch : [254] Train loss : [0.013458261000258582] Val Score : [0.9165787375726882])\n","Epoch : [255] Train loss : [0.013955962578100818] Val Score : [0.9165787375726882])\n","Epoch : [256] Train loss : [0.012405615832124437] Val Score : [0.9165787375726882])\n","Epoch : [257] Train loss : [0.01412883254566363] Val Score : [0.9165787375726882])\n","Epoch : [258] Train loss : [0.013810531502323491] Val Score : [0.9165787375726882])\n","Epoch : [259] Train loss : [0.01239115824656827] Val Score : [0.9165787375726882])\n","Epoch : [260] Train loss : [0.014056195371917315] Val Score : [0.9165787375726882])\n","Epoch : [261] Train loss : [0.014315384174031871] Val Score : [0.9165787375726882])\n","Epoch : [262] Train loss : [0.011757669837347098] Val Score : [0.9165787375726882])\n","Epoch : [263] Train loss : [0.01282562900866781] Val Score : [0.9165787375726882])\n","Epoch : [264] Train loss : [0.01220541780016252] Val Score : [0.9165787375726882])\n","Epoch : [265] Train loss : [0.016480699314602783] Val Score : [0.9165787375726882])\n","Epoch : [266] Train loss : [0.01458124044750418] Val Score : [0.9165787375726882])\n","Epoch : [267] Train loss : [0.014921667453433787] Val Score : [0.9165787375726882])\n","Epoch : [268] Train loss : [0.013723610368158137] Val Score : [0.9165787375726882])\n","Epoch : [269] Train loss : [0.013094559444912843] Val Score : [0.9165787375726882])\n","Epoch : [270] Train loss : [0.01454633181648595] Val Score : [0.9165787375726882])\n","Epoch : [271] Train loss : [0.012099548242986202] Val Score : [0.9165787375726882])\n","Epoch : [272] Train loss : [0.014089174036468779] Val Score : [0.9165787375726882])\n","Epoch : [273] Train loss : [0.014597036210553986] Val Score : [0.9165787375726882])\n","Epoch : [274] Train loss : [0.013812639218355929] Val Score : [0.9165787375726882])\n","Epoch : [275] Train loss : [0.0135255917640669] Val Score : [0.9165787375726882])\n","Epoch : [276] Train loss : [0.011971337055521352] Val Score : [0.9165787375726882])\n","Epoch : [277] Train loss : [0.015171309134789876] Val Score : [0.9165787375726882])\n","Epoch : [278] Train loss : [0.012218510865100793] Val Score : [0.9165787375726882])\n","Epoch : [279] Train loss : [0.013563859276473522] Val Score : [0.9165787375726882])\n","Epoch : [280] Train loss : [0.014957159624568053] Val Score : [0.9165787375726882])\n","Epoch : [281] Train loss : [0.012207600022000926] Val Score : [0.9165787375726882])\n","Epoch : [282] Train loss : [0.011990632595760482] Val Score : [0.9165787375726882])\n","Epoch : [283] Train loss : [0.015251153680895056] Val Score : [0.9165787375726882])\n","Epoch : [284] Train loss : [0.012759781974766935] Val Score : [0.9165787375726882])\n","Epoch : [285] Train loss : [0.012069055544478553] Val Score : [0.9165787375726882])\n","Epoch : [286] Train loss : [0.01398258124079023] Val Score : [0.9165787375726882])\n","Epoch : [287] Train loss : [0.013467837125062943] Val Score : [0.9165787375726882])\n","Epoch : [288] Train loss : [0.013588961879057544] Val Score : [0.9165787375726882])\n","Epoch : [289] Train loss : [0.01231068731950862] Val Score : [0.9165787375726882])\n","Epoch : [290] Train loss : [0.015621941802757127] Val Score : [0.9165787375726882])\n","Epoch : [291] Train loss : [0.01303980459592172] Val Score : [0.9165787375726882])\n","Epoch : [292] Train loss : [0.012946504833442824] Val Score : [0.9165787375726882])\n","Epoch : [293] Train loss : [0.013416294806769915] Val Score : [0.9165787375726882])\n","Epoch : [294] Train loss : [0.014116142610354083] Val Score : [0.9165787375726882])\n","Epoch : [295] Train loss : [0.014242531465632575] Val Score : [0.9165787375726882])\n","Epoch : [296] Train loss : [0.013268884803567613] Val Score : [0.9165787375726882])\n","Epoch : [297] Train loss : [0.01398379196013723] Val Score : [0.9165787375726882])\n","Epoch : [298] Train loss : [0.011706077759819371] Val Score : [0.9165787375726882])\n","Epoch : [299] Train loss : [0.012236034896756922] Val Score : [0.9165787375726882])\n","Epoch : [300] Train loss : [0.014072193498057979] Val Score : [0.9165787375726882])\n","Epoch : [301] Train loss : [0.013140941171773843] Val Score : [0.9165787375726882])\n","Epoch : [302] Train loss : [0.012326584463672978] Val Score : [0.9165787375726882])\n","Epoch : [303] Train loss : [0.012278580106794834] Val Score : [0.9165787375726882])\n","Epoch : [304] Train loss : [0.0117289022143398] Val Score : [0.9165787375726882])\n","Epoch : [305] Train loss : [0.012967059122664588] Val Score : [0.9165787375726882])\n","Epoch : [306] Train loss : [0.01301165936248643] Val Score : [0.9165787375726882])\n","Epoch : [307] Train loss : [0.012867202849260398] Val Score : [0.9165787375726882])\n","Epoch : [308] Train loss : [0.01215234279100384] Val Score : [0.9165787375726882])\n","Epoch : [309] Train loss : [0.013688024931720324] Val Score : [0.9165787375726882])\n","Epoch : [310] Train loss : [0.013074816071561404] Val Score : [0.9165787375726882])\n","Epoch : [311] Train loss : [0.014102722784238202] Val Score : [0.9165787375726882])\n","Epoch : [312] Train loss : [0.012699743865856103] Val Score : [0.9165787375726882])\n","Epoch : [313] Train loss : [0.012322012335062027] Val Score : [0.9165787375726882])\n","Epoch : [314] Train loss : [0.012465330372963632] Val Score : [0.9165787375726882])\n","Epoch : [315] Train loss : [0.01470275835267135] Val Score : [0.9165787375726882])\n","Epoch : [316] Train loss : [0.012774620205163956] Val Score : [0.9165787375726882])\n","Epoch : [317] Train loss : [0.013740340912980693] Val Score : [0.9165787375726882])\n","Epoch : [318] Train loss : [0.012968287004956178] Val Score : [0.9165787375726882])\n","Epoch : [319] Train loss : [0.015086387151053973] Val Score : [0.9165787375726882])\n","Epoch : [320] Train loss : [0.01249623644564833] Val Score : [0.9165787375726882])\n","Epoch : [321] Train loss : [0.014223197874213969] Val Score : [0.9165787375726882])\n","Epoch : [322] Train loss : [0.013699307505573546] Val Score : [0.9165787375726882])\n","Epoch : [323] Train loss : [0.012307542509266309] Val Score : [0.9165787375726882])\n","Epoch : [324] Train loss : [0.013594853026526315] Val Score : [0.9165787375726882])\n","Epoch : [325] Train loss : [0.013969519042543002] Val Score : [0.9165787375726882])\n","Epoch : [326] Train loss : [0.012683126144111156] Val Score : [0.9165787375726882])\n","Epoch : [327] Train loss : [0.015953646839729378] Val Score : [0.9165787375726882])\n","Epoch : [328] Train loss : [0.014255388772913389] Val Score : [0.9165787375726882])\n","Epoch : [329] Train loss : [0.014130104732300554] Val Score : [0.9165787375726882])\n","Epoch : [330] Train loss : [0.01355988918138402] Val Score : [0.9165787375726882])\n","Epoch : [331] Train loss : [0.011410192852573735] Val Score : [0.9165787375726882])\n","Epoch : [332] Train loss : [0.012542002435241426] Val Score : [0.9165787375726882])\n","Epoch : [333] Train loss : [0.013395839370787144] Val Score : [0.9165787375726882])\n","Epoch : [334] Train loss : [0.01397578724260841] Val Score : [0.9165787375726882])\n","Epoch : [335] Train loss : [0.01416679032679115] Val Score : [0.9165787375726882])\n","Epoch : [336] Train loss : [0.013466073998383113] Val Score : [0.9165787375726882])\n","Epoch : [337] Train loss : [0.015001451995755945] Val Score : [0.9165787375726882])\n","Epoch : [338] Train loss : [0.01426471849637372] Val Score : [0.9165787375726882])\n","Epoch : [339] Train loss : [0.011851906909474305] Val Score : [0.9165787375726882])\n","Epoch : [340] Train loss : [0.013146223766463143] Val Score : [0.9165787375726882])\n","Epoch : [341] Train loss : [0.013133852875658445] Val Score : [0.9165787375726882])\n","Epoch : [342] Train loss : [0.011275689117610455] Val Score : [0.9165787375726882])\n","Epoch : [343] Train loss : [0.013069452185715948] Val Score : [0.9165787375726882])\n","Epoch : [344] Train loss : [0.013301548148904527] Val Score : [0.9165787375726882])\n","Epoch : [345] Train loss : [0.012081957023058618] Val Score : [0.9165787375726882])\n","Epoch : [346] Train loss : [0.012139342060046536] Val Score : [0.9165787375726882])\n","Epoch : [347] Train loss : [0.011704967490264348] Val Score : [0.9165787375726882])\n","Epoch : [348] Train loss : [0.012604461716754096] Val Score : [0.9165787375726882])\n","Epoch : [349] Train loss : [0.013244987731533391] Val Score : [0.9165787375726882])\n","Epoch : [350] Train loss : [0.01374433801642486] Val Score : [0.9165787375726882])\n","Epoch : [351] Train loss : [0.01158405002206564] Val Score : [0.9165787375726882])\n","Epoch : [352] Train loss : [0.012116135364132268] Val Score : [0.9165787375726882])\n","Epoch : [353] Train loss : [0.014348483378333705] Val Score : [0.9165787375726882])\n","Epoch : [354] Train loss : [0.012515757232904434] Val Score : [0.9165787375726882])\n","Epoch : [355] Train loss : [0.014417759009769984] Val Score : [0.9165787375726882])\n","Epoch : [356] Train loss : [0.014185752187456404] Val Score : [0.9165787375726882])\n","Epoch : [357] Train loss : [0.013095382467976638] Val Score : [0.9165787375726882])\n","Epoch : [358] Train loss : [0.011927064375153609] Val Score : [0.9165787375726882])\n","Epoch : [359] Train loss : [0.014139614866248198] Val Score : [0.9165787375726882])\n","Epoch : [360] Train loss : [0.0132056771378432] Val Score : [0.9165787375726882])\n","Epoch : [361] Train loss : [0.01483308816594737] Val Score : [0.9165787375726882])\n","Epoch : [362] Train loss : [0.013876949436962605] Val Score : [0.9165787375726882])\n","Epoch : [363] Train loss : [0.014146446383425168] Val Score : [0.9165787375726882])\n","Epoch : [364] Train loss : [0.014754738259528364] Val Score : [0.9165787375726882])\n","Epoch : [365] Train loss : [0.013703141494521074] Val Score : [0.9165787375726882])\n","Epoch : [366] Train loss : [0.014516893774271011] Val Score : [0.9165787375726882])\n","Epoch : [367] Train loss : [0.013243591945086206] Val Score : [0.9165787375726882])\n","Epoch : [368] Train loss : [0.01616190533552851] Val Score : [0.9165787375726882])\n","Epoch : [369] Train loss : [0.012653265281447343] Val Score : [0.9165787375726882])\n","Epoch : [370] Train loss : [0.014008799966956888] Val Score : [0.9165787375726882])\n","Epoch : [371] Train loss : [0.014018101617693901] Val Score : [0.9165787375726882])\n","Epoch : [372] Train loss : [0.015171570171202933] Val Score : [0.9165787375726882])\n","Epoch : [373] Train loss : [0.012465115902679307] Val Score : [0.9165787375726882])\n","Epoch : [374] Train loss : [0.012617545601512705] Val Score : [0.9165787375726882])\n","Epoch : [375] Train loss : [0.013529028477413314] Val Score : [0.9165787375726882])\n","Epoch : [376] Train loss : [0.01199301318930728] Val Score : [0.9165787375726882])\n","Epoch : [377] Train loss : [0.012073139793106489] Val Score : [0.9165787375726882])\n","Epoch : [378] Train loss : [0.014382019639015198] Val Score : [0.9165787375726882])\n","Epoch : [379] Train loss : [0.013795666263571807] Val Score : [0.9165787375726882])\n","Epoch : [380] Train loss : [0.01219622977077961] Val Score : [0.9165787375726882])\n","Epoch : [381] Train loss : [0.013563384568052632] Val Score : [0.9165787375726882])\n","Epoch : [382] Train loss : [0.014177414854722363] Val Score : [0.9165787375726882])\n","Epoch : [383] Train loss : [0.014318511289145266] Val Score : [0.9165787375726882])\n","Epoch : [384] Train loss : [0.013916640808539731] Val Score : [0.9165787375726882])\n","Epoch : [385] Train loss : [0.01531330549291202] Val Score : [0.9165787375726882])\n","Epoch : [386] Train loss : [0.016586168136979853] Val Score : [0.9165787375726882])\n","Epoch : [387] Train loss : [0.012200402095913887] Val Score : [0.9165787375726882])\n","Epoch : [388] Train loss : [0.013981564768723078] Val Score : [0.9165787375726882])\n","Epoch : [389] Train loss : [0.012050032881753785] Val Score : [0.9165787375726882])\n","Epoch : [390] Train loss : [0.012088440624730927] Val Score : [0.9165787375726882])\n","Epoch : [391] Train loss : [0.014110351779631205] Val Score : [0.9165787375726882])\n","Epoch : [392] Train loss : [0.013475278592003244] Val Score : [0.9165787375726882])\n","Epoch : [393] Train loss : [0.014868373184331827] Val Score : [0.9165787375726882])\n","Epoch : [394] Train loss : [0.01322427112609148] Val Score : [0.9165787375726882])\n","Epoch : [395] Train loss : [0.01265189064932721] Val Score : [0.9165787375726882])\n","Epoch : [396] Train loss : [0.013182385026344232] Val Score : [0.9165787375726882])\n","Epoch : [397] Train loss : [0.012593845038541726] Val Score : [0.9165787375726882])\n","Epoch : [398] Train loss : [0.014371272708688463] Val Score : [0.9165787375726882])\n","Epoch : [399] Train loss : [0.013006553186901979] Val Score : [0.9165787375726882])\n"]}]},{"cell_type":"markdown","metadata":{"id":"LikG8E2yw_2C"},"source":["### 추론"]},{"cell_type":"code","source":["# 학습된 내용 불러오기\n","model = AutoEncoder()\n","model.load_state_dict(torch.load('./best_model2.pth'))\n","model = nn.DataParallel(model)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DasDEq98XI4f","executionInfo":{"status":"ok","timestamp":1658830796395,"user_tz":-540,"elapsed":1033,"user":{"displayName":"이환수","userId":"08991315129480263510"}},"outputId":"29533802-0b71-4f72-eff3-86a1d7822dd3"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataParallel(\n","  (module): AutoEncoder(\n","    (Encoder): Sequential(\n","      (0): Linear(in_features=30, out_features=64, bias=True)\n","      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): PReLU(num_parameters=1)\n","      (3): Linear(in_features=64, out_features=128, bias=True)\n","      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): PReLU(num_parameters=1)\n","    )\n","    (Decoder): Sequential(\n","      (0): Linear(in_features=128, out_features=64, bias=True)\n","      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): PReLU(num_parameters=1)\n","      (3): Linear(in_features=64, out_features=30, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["test_dataset = MyDataset(test_df, False)\n","test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=2)"],"metadata":{"id":"OyoKdvTVXFtv","executionInfo":{"status":"ok","timestamp":1658830803794,"user_tz":-540,"elapsed":735,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","execution_count":33,"metadata":{"id":"tfsaY4q8w_2F","executionInfo":{"status":"ok","timestamp":1658830807759,"user_tz":-540,"elapsed":1634,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["preds = prediction(model, 0.95, test_loader, device)"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"Dam9mtoow_2G","executionInfo":{"status":"ok","timestamp":1658831230410,"user_tz":-540,"elapsed":763,"user":{"displayName":"이환수","userId":"08991315129480263510"}}},"outputs":[],"source":["submit = pd.read_csv('./drive/MyDrive/data/sample_submission.csv')\n","submit['Class'] = preds\n","submit.to_csv('./drive/MyDrive/autoencoder_test_hwan3.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.6 ('study')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"c530038a4968235b14954dfb7e9ce27eac1d97b010045a73365830ad480ab54b"}},"colab":{"name":"AutoEncoder_study.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}